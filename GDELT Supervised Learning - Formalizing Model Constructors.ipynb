{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import csv, sqlite3\n",
    "%matplotlib inline\n",
    "\n",
    "from GDELT_utils import GDELT_columns, usecols, dtype_dict, \\\n",
    "                        cameo_dict, map_cameo_to_text, \\\n",
    "                        state_dict, mem_usage, state_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"gdelt.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdelt_sql = pd.read_sql_query(\"SELECT SQLDATE, Actor1CountryCode, Actor2CountryCode, \\\n",
    "                              Actor1Type1Code, Actor2Type1Code, \\\n",
    "                            Actor1Geo_CountryCode, Actor2Geo_CountryCode, \\\n",
    "                            EventRootCode, AVG(NumMentions), AVG(AvgTone) \\\n",
    "                          FROM gdelt \\\n",
    "                          WHERE SQLDATE > \\\"2017-05-01\\\" AND SQLDATE < \\\"2017-08-01\\\" \\\n",
    "                          GROUP BY SQLDATE, Actor1CountryCode, Actor2CountryCode, \\\n",
    "                          Actor1Type1Code, Actor2Type1Code, \\\n",
    "                          Actor1Geo_CountryCode, Actor2Geo_CountryCode, EventRootCode\", con)\n",
    "# aggregate data by\n",
    "# Date Actor1Code Actor2Code Actor1Geo_CountryCode Actor2Geo_CountryCode EventRootCode -> Mean AvgTone\n",
    "\n",
    "# Features Actor1Code Actor2Code Actor1Geo_CountryCode Actor2Geo_CountryCode NumMentions EventRootCode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7514833 entries, 0 to 7514832\n",
      "Data columns (total 10 columns):\n",
      "SQLDATE                  object\n",
      "Actor1CountryCode        object\n",
      "Actor2CountryCode        object\n",
      "Actor1Type1Code          object\n",
      "Actor2Type1Code          object\n",
      "Actor1Geo_CountryCode    object\n",
      "Actor2Geo_CountryCode    object\n",
      "EventRootCode            object\n",
      "AVG(NumMentions)         float64\n",
      "AVG(AvgTone)             float64\n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 573.3+ MB\n"
     ]
    }
   ],
   "source": [
    "gdelt_sql.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.000000       1341170\n",
       "10.000000       869253\n",
       "1.000000        726505\n",
       "4.000000        683948\n",
       "6.000000        564844\n",
       "5.000000        469075\n",
       "3.000000        422756\n",
       "8.000000        352061\n",
       "20.000000       141490\n",
       "12.000000       111735\n",
       "7.000000        102068\n",
       "2.500000         60906\n",
       "16.000000        57205\n",
       "9.000000         56854\n",
       "15.000000        54729\n",
       "1.500000         52123\n",
       "30.000000        47712\n",
       "3.500000         41762\n",
       "18.000000        35898\n",
       "7.500000         35746\n",
       "4.500000         34621\n",
       "14.000000        33388\n",
       "5.500000         29664\n",
       "24.000000        26790\n",
       "11.000000        24702\n",
       "6.500000         24417\n",
       "40.000000        22842\n",
       "3.333333         22189\n",
       "13.000000        18548\n",
       "2.666667         17189\n",
       "                ...   \n",
       "57.158730            1\n",
       "1011.666667          1\n",
       "48.241135            1\n",
       "21.488095            1\n",
       "73.823529            1\n",
       "260.750000           1\n",
       "20.036765            1\n",
       "54.631579            1\n",
       "34.083832            1\n",
       "259.375000           1\n",
       "9.327044             1\n",
       "18.608187            1\n",
       "17.246154            1\n",
       "199.200000           1\n",
       "24.810127            1\n",
       "111.366667           1\n",
       "51.818182            1\n",
       "25.248175            1\n",
       "6.394366             1\n",
       "22.057592            1\n",
       "3.517857             1\n",
       "14.345588            1\n",
       "38.866667            1\n",
       "64.222222            1\n",
       "10.525000            1\n",
       "165.076923           1\n",
       "12.449275            1\n",
       "11.503401            1\n",
       "7.314815             1\n",
       "63.465116            1\n",
       "Name: AVG(NumMentions), Length: 42033, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_sql['AVG(NumMentions)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7514833, 10)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_sql.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_sql.to_csv(\"gdelt_agg_big.csv\", chunksize=100, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "gdelt_raw = pd.read_csv(\"gdelt_agg_big.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt = pd.read_csv(\"gdelt_agg_big.csv\", dtype={\"EventRootCode\": \"category\",\n",
    "                                               \"Actor1CountryCode\": \"category\", \n",
    "                                               \"Actor2CountryCode\": \"category\",\n",
    "                                               \"Actor1Geo_CountryCode\": \"category\", \n",
    "                                               \"Actor2Geo_CountryCode\": \"category\",\n",
    "                                               \"Actor1Type1Code\": \"category\",\n",
    "                                               \"Actor2Type1Code\": \"category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SQLDATE', 'Actor1CountryCode', 'Actor2CountryCode', 'Actor1Type1Code',\n",
       "       'Actor2Type1Code', 'Actor1Geo_CountryCode', 'Actor2Geo_CountryCode',\n",
       "       'EventRootCode', 'AVG(NumMentions)', 'AVG(AvgTone)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interest = [\"SQLDATE\",\n",
    "            \"AvgTone\", \"NumMentions\", \"EventRootCode\",\n",
    "            \"Actor1CountryCode\", \"Actor2CountryCode\",\n",
    "            \"Actor1Geo_CountryCode\", \"Actor2Geo_CountryCode\"]\n",
    "\n",
    "categories = [\"EventRootCode\",\n",
    "            \"Actor1CountryCode\", \"Actor2CountryCode\",\n",
    "            \"Actor1Geo_CountryCode\", \"Actor2Geo_CountryCode\"]\n",
    "\n",
    "gdelt = gdelt.drop(labels=gdelt[(gdelt['EventRootCode'] == \"--\")].index)\n",
    "\n",
    "for category_col in categories:\n",
    "    gdelt[category_col] = gdelt[category_col].astype('category') \\\n",
    "                                    .cat.remove_unused_categories()\n",
    "    \n",
    "gdelt['SQLDATE'] = pd.to_datetime(gdelt['SQLDATE'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_sample = gdelt.sample(frac=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_tones = gdelt_sample['AVG(AvgTone)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_tones = gdelt_sample['AVG(AvgTone)']\n",
    "def dim_reduce(column):\n",
    "    gdelt_cntry = gdelt_sample[column]\n",
    "\n",
    "    one_hot = pd.get_dummies(gdelt_cntry)\n",
    "    \n",
    "    one_hot_tone = pd.concat([gdelt_tones, one_hot], axis=1)\n",
    "\n",
    "    avg_avgtone_mean = one_hot_tone['AVG(AvgTone)'].mean()\n",
    "    avg_avgtone_std = one_hot_tone['AVG(AvgTone)'].std()\n",
    "\n",
    "    country_tones = []\n",
    "    country_info = []\n",
    "    for column in one_hot.columns:\n",
    "        temp = one_hot_tone[[column, 'AVG(AvgTone)']]\n",
    "        country = temp[temp[column] == 1]\n",
    "        if len(country) < 10:\n",
    "            #print(country)\n",
    "            continue\n",
    "        column_means = temp.groupby(column).mean()['AVG(AvgTone)']\n",
    "        country_tones.append(column_means)\n",
    "        country_info.append((column, column_means[0] - column_means[1], np.absolute(column_means[0] - column_means[1]), \n",
    "                            (temp[column].sum()), ttest_1samp(country, avg_avgtone_mean).pvalue[1]))\n",
    "\n",
    "    cntry_spec = pd.DataFrame(country_info, columns=[\"Country\", \"AvgTone_diff\", \"AvgTone_mag\", \"Num\", \"p-value\"])\n",
    "\n",
    "    low_decs = cntry_spec[((cntry_spec['p-value'] > 0.0001) & ((cntry_spec['AvgTone_mag'] < 1) & \\\n",
    "               (cntry_spec['AvgTone_diff'] < 0)))]['Country']\n",
    "\n",
    "    low_incs = cntry_spec[((cntry_spec['p-value'] > 0.0001) & ((cntry_spec['AvgTone_mag'] < 1) & \\\n",
    "               (cntry_spec['AvgTone_diff'] > 0)))]['Country']\n",
    "\n",
    "    low_p_value = cntry_spec[((cntry_spec['p-value'] > 0.0001) & ~((cntry_spec['AvgTone_mag'] < 1) & \\\n",
    "               (cntry_spec['AvgTone_diff'] < 0)) & ~((cntry_spec['AvgTone_mag'] < 1) & \\\n",
    "               (cntry_spec['AvgTone_diff'] > 0)))]['Country']\n",
    "    \n",
    "    return low_decs, low_incs, low_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_decs_A1CC, low_incs_A1CC, low_p_value_A1CC = dim_reduce('Actor1CountryCode')\n",
    "low_decs_A2CC, low_incs_A2CC, low_p_value_A2CC = dim_reduce('Actor2CountryCode')\n",
    "low_decs_A1GCC, low_incs_A1GCC, low_p_value_A1GCC = dim_reduce('Actor1Geo_CountryCode')\n",
    "low_decs_A2GCC, low_incs_A2GCC, low_p_value_A2GCC = dim_reduce('Actor2Geo_CountryCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_df = gdelt_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_missing(x, low_decs, low_incs, low_p_value, translation):\n",
    "    #if x in l:\n",
    "    #    return x\n",
    "    if x == \"nan\":\n",
    "        return \"UNKNOWN\"\n",
    "    elif x in low_decs:\n",
    "        return \"LOW_DEC\"\n",
    "    elif x in low_incs:\n",
    "        return \"LOW_INCS\"\n",
    "    elif x in low_p_value:\n",
    "        return \"LOW_P_VALUE\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def unify_cats(data, category, low_decs, low_incs, low_p_value):\n",
    "    low_decs_unique = low_decs.unique()\n",
    "    low_decs_unique = low_incs.unique()\n",
    "    low_p_value_unique = low_p_value.unique()\n",
    "    data[(category + '_unify')] = data[category].astype(str) \\\n",
    "                                                .apply(lambda x: map_missing(x, low_decs_unique, \n",
    "                                                                             low_decs_unique, \n",
    "                                                                             low_p_value_unique, \n",
    "                                                                             \"OTHER\")) \\\n",
    "                                                .astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unify_cats(model_df, 'Actor1CountryCode', low_decs_A1CC, low_incs_A1CC, low_p_value_A1CC)\n",
    "unify_cats(model_df, 'Actor2CountryCode', low_decs_A2CC, low_incs_A2CC, low_p_value_A2CC)\n",
    "unify_cats(model_df, 'Actor1Geo_CountryCode', low_decs_A1GCC, low_incs_A1GCC, low_p_value_A1GCC)\n",
    "unify_cats(model_df, 'Actor2Geo_CountryCode', low_decs_A2GCC, low_incs_A2GCC, low_p_value_A2GCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_df['norm_NumMentions'] = (model_df['AVG(NumMentions)'] - model_df['AVG(NumMentions)'].mean())/ \\\n",
    "                                        model_df['AVG(NumMentions)'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_df = model_df.drop(['Actor1CountryCode', 'Actor2CountryCode', 'Actor1Geo_CountryCode', \n",
    "#               'Actor2Geo_CountryCode', 'AVG(NumMentions)', 'SQLDATE'], axis=1)\n",
    "\n",
    "Actor1CC_one_hot = pd.get_dummies(model_df['Actor1CountryCode_unify'], prefix=\"Actor1CountryCode\")\n",
    "Actor2CC_one_hot = pd.get_dummies(model_df['Actor2CountryCode_unify'], prefix=\"Actor2CountryCode\")\n",
    "Actor1CCGeo_one_hot = pd.get_dummies(model_df['Actor1Geo_CountryCode_unify'], prefix=\"Actor1Geo_CountryCode\")\n",
    "Actor2CCGeo_one_hot = pd.get_dummies(model_df['Actor2Geo_CountryCode_unify'], prefix=\"Actor2Geo_CountryCode\")\n",
    "EventRoot_one_hot = pd.get_dummies(model_df['EventRootCode'], prefix=\"EventRootCode\")\n",
    "\n",
    "one_hot_encoding = pd.concat([Actor1CC_one_hot, Actor2CC_one_hot, Actor1CCGeo_one_hot, \n",
    "                              Actor2CCGeo_one_hot, EventRoot_one_hot], axis=1)\n",
    "\n",
    "model_df_hot = pd.concat([model_df, one_hot_encoding], axis=1).drop(['Actor1CountryCode_unify',\n",
    "                                                                    'Actor2CountryCode_unify',\n",
    "                                                                    'Actor1Geo_CountryCode_unify',\n",
    "                                                                    'Actor2Geo_CountryCode_unify'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = model_df_hot.drop(['AVG(AvgTone)'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(model_df_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "Y = train['AVG(AvgTone)'].values.reshape(-1, 1)\n",
    "X = train[feature_columns]\n",
    "regr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24057144216501747"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "regr = Ridge()\n",
    "Y = train['AVG(AvgTone)'].values.reshape(-1, 1)\n",
    "X = train[feature_columns]\n",
    "regr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24050873555027785"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_missing(x, l, translation):\n",
    "    if x in l:\n",
    "        return x\n",
    "    elif x == \"nan\":\n",
    "        return \"UNKNOWN\"\n",
    "    else:\n",
    "        return translation\n",
    "\n",
    "def unify_rare_cats(data, category, cut_off):\n",
    "    vc = data[category].value_counts()\n",
    "    past_cut_off = (vc/len(data)) > cut_off\n",
    "    remaining = list(vc[past_cut_off].index)\n",
    "    data[(category + '_unify')] = data[category].astype(str) \\\n",
    "                                                .apply(lambda x: map_missing(x, remaining, \"OTHER\")) \\\n",
    "                                                .astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_sample_rem = gdelt_sample.drop(['Actor1Geo_CountryCode', 'Actor2Geo_CountryCode', 'SQLDATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unify_rare_cats(gdelt_sample, 'Actor1CountryCode', .005)\n",
    "unify_rare_cats(gdelt_sample, 'Actor2CountryCode', .005)\n",
    "unify_rare_cats(gdelt_sample, 'Actor1Geo_CountryCode', .005)\n",
    "unify_rare_cats(gdelt_sample, 'Actor2Geo_CountryCode', .005)\n",
    "\n",
    "unify_rare_cats(gdelt_sample_rem, 'Actor1CountryCode', .005)\n",
    "unify_rare_cats(gdelt_sample_rem, 'Actor2CountryCode', .005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_sample['norm_NumMentions'] = (gdelt_sample['AVG(NumMentions)'] - gdelt_sample['AVG(NumMentions)'].mean())/ \\\n",
    "                                        gdelt_sample['AVG(NumMentions)'].std()\n",
    "    \n",
    "gdelt_sample_rem['norm_NumMentions'] = (gdelt_sample_rem['AVG(NumMentions)'] - gdelt_sample_rem['AVG(NumMentions)'].mean())/ \\\n",
    "                                        gdelt_sample_rem['AVG(NumMentions)'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Actor1CC_one_hot = pd.get_dummies(gdelt_sample['Actor1CountryCode_unify'], prefix=\"Actor1CountryCode\")\n",
    "Actor2CC_one_hot = pd.get_dummies(gdelt_sample['Actor2CountryCode_unify'], prefix=\"Actor2CountryCode\")\n",
    "Actor1CCGeo_one_hot = pd.get_dummies(gdelt_sample['Actor1Geo_CountryCode_unify'], prefix=\"Actor1Geo_CountryCode\")\n",
    "Actor2CCGeo_one_hot = pd.get_dummies(gdelt_sample['Actor2Geo_CountryCode_unify'], prefix=\"Actor2Geo_CountryCode\")\n",
    "EventRoot_one_hot = pd.get_dummies(gdelt_sample['EventRootCode'], prefix=\"EventRootCode\")\n",
    "\n",
    "one_hot_encoding = pd.concat([Actor1CC_one_hot, Actor2CC_one_hot, Actor1CCGeo_one_hot, \n",
    "                              Actor2CCGeo_one_hot, EventRoot_one_hot], axis=1)\n",
    "\n",
    "gdelt_sample = pd.concat([gdelt_sample, one_hot_encoding], axis=1)\n",
    "\n",
    "Actor1CC_one_hot_rem = pd.get_dummies(gdelt_sample_rem['Actor1CountryCode_unify'], prefix=\"Actor1CountryCode\")\n",
    "Actor2CC_one_hot_rem = pd.get_dummies(gdelt_sample_rem['Actor2CountryCode_unify'], prefix=\"Actor2CountryCode\")\n",
    "EventRoot_one_hot_rem = pd.get_dummies(gdelt_sample_rem['EventRootCode'], prefix=\"EventRootCode\")\n",
    "\n",
    "one_hot_encoding_rem = pd.concat([Actor1CC_one_hot_rem, Actor2CC_one_hot_rem, EventRoot_one_hot_rem], axis=1)\n",
    "\n",
    "gdelt_sample_rem = pd.concat([gdelt_sample_rem, one_hot_encoding_rem], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218524, 202)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218524, 103)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_sample_rem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_columns = list(one_hot_encoding.columns)\n",
    "model_columns.append('norm_NumMentions')\n",
    "feature_columns = model_columns.copy()\n",
    "model_columns.append('AVG(AvgTone)')\n",
    "\n",
    "model_columns_rem = list(one_hot_encoding_rem.columns)\n",
    "model_columns_rem.append('norm_NumMentions')\n",
    "feature_columns_rem = model_columns_rem.copy()\n",
    "model_columns_rem.append('AVG(AvgTone)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_sample_m = gdelt_sample[model_columns].copy()\n",
    "\n",
    "gdelt_sample_rem_m = gdelt_sample_rem[model_columns_rem].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(gdelt_sample_m, test_size=0.25, random_state=42)\n",
    "\n",
    "train_rem, test_rem = train_test_split(gdelt_sample_rem_m, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163893, 186)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163893, 96)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared:\n",
      "0.21195525887786848\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(gdelt_sample_m, test_size=0.25, random_state=42)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "Y = train['AVG(AvgTone)']\n",
    "X = train[feature_columns]\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(regr.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared:\n",
      "0.19612340075559853\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "Y = train_rem['AVG(AvgTone)']\n",
    "X = train_rem[feature_columns_rem]\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(regr.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          11.9990           20.34s\n",
      "         2          11.8767           20.96s\n",
      "         3          11.7423           21.06s\n",
      "         4          11.6426           20.51s\n",
      "         5          11.5372           20.56s\n",
      "         6          11.4539           20.20s\n",
      "         7          11.3692           20.15s\n",
      "         8          11.2915           20.01s\n",
      "         9          11.2241           19.67s\n",
      "        10          11.1566           19.59s\n",
      "        20          10.7166           17.05s\n",
      "        30          10.4914           14.72s\n",
      "        40          10.3520           12.51s\n",
      "        50          10.2515           10.34s\n",
      "        60          10.1728            8.22s\n",
      "        70          10.1086            6.14s\n",
      "        80          10.0549            4.07s\n",
      "        90          10.0058            2.04s\n",
      "       100           9.9647            0.00s\n",
      "\n",
      "R-squared:\n",
      "0.17984288931184345\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, verbose=True)\n",
    "Y = train['AVG(AvgTone)']\n",
    "X = train[feature_columns]\n",
    "gbr.fit(X, Y)\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(gbr.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          11.9990           11.26s\n",
      "         2          11.8767           11.19s\n",
      "         3          11.7423           11.22s\n",
      "         4          11.6426           10.99s\n",
      "         5          11.5372           11.07s\n",
      "         6          11.4539           11.00s\n",
      "         7          11.3697           10.88s\n",
      "         8          11.2921           10.84s\n",
      "         9          11.2248           10.82s\n",
      "        10          11.1579           10.88s\n",
      "        20          10.7201            9.95s\n",
      "        30          10.4975            8.66s\n",
      "        40          10.3661            7.26s\n",
      "        50          10.2721            5.96s\n",
      "        60          10.2009            4.71s\n",
      "        70          10.1437            3.50s\n",
      "        80          10.0983            2.31s\n",
      "        90          10.0602            1.15s\n",
      "       100          10.0275            0.00s\n",
      "\n",
      "R-squared:\n",
      "0.17466966269757112\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, verbose=True)\n",
    "Y = train_rem['AVG(AvgTone)']\n",
    "X = train_rem[feature_columns_rem]\n",
    "gbr.fit(X, Y)\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(gbr.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          11.9388           56.12s\n",
      "         2          11.7679           58.00s\n",
      "         3          11.5662            1.01m\n",
      "         4          11.4354           58.12s\n",
      "         5          11.2817           58.91s\n",
      "         6          11.1773           57.53s\n",
      "         7          11.0588           57.94s\n",
      "         8          10.9625           58.21s\n",
      "         9          10.8883           57.18s\n",
      "        10          10.8141           57.32s\n",
      "        20          10.4229           52.19s\n",
      "        30          10.2504           49.93s\n",
      "        40          10.1417           47.97s\n",
      "        50          10.0616           45.95s\n",
      "        60          10.0019           45.79s\n",
      "        70           9.9554           42.34s\n",
      "        80           9.9176           38.86s\n",
      "        90           9.8828           35.80s\n",
      "       100           9.8542           33.00s\n",
      "       200           9.6835           10.36s\n",
      "\n",
      "R-squared:\n",
      "0.20653569805723182\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=3, verbose=True, n_estimators=250)\n",
    "Y = train_rem['AVG(AvgTone)']\n",
    "X = train_rem[feature_columns_rem]\n",
    "gbr.fit(X, Y)\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(gbr.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared:\n",
      "0.19626564733644636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.8515251 ,  0.84879249,  0.42976662,  0.58719902,  0.24300694,\n",
       "        0.77631464,  0.86328756,  0.11948364, -0.57047295,  0.71796266,\n",
       "        0.43715595,  0.52781539,  0.27002181, -0.08290007,  0.69548257,\n",
       "       -0.69176825, -0.75654196, -0.39573903,  0.29765846, -0.43138564,\n",
       "        0.82775763,  0.51355615,  0.16058804,  0.23049128,  0.17102605,\n",
       "        0.31995076, -0.36282578, -0.18070882,  0.28522125, -0.77060142,\n",
       "       -1.0950767 , -0.61206347, -0.25294739, -0.4342424 , -1.14120839,\n",
       "       -0.29421253, -0.51348242, -0.07056624,  0.18572966, -0.68173321,\n",
       "        0.9156716 ,  0.67602895,  0.08100082,  0.65746073,  0.77851383,\n",
       "        0.15983953, -0.51390072,  0.61131216,  0.52273344,  0.60329033,\n",
       "        0.21400534, -0.01603856,  0.62005944, -0.73601223, -0.55837229,\n",
       "       -0.09700976,  0.3706473 ,  0.93742817,  0.56769648, -0.0497552 ,\n",
       "        0.06074978,  0.29155451, -0.49646468, -0.48462042, -0.88252197,\n",
       "       -0.93761505, -0.61455413, -0.28073163, -0.53419266, -1.13539194,\n",
       "       -0.37437787,  0.13222604,  0.19307387,  0.        ,  0.60207854,\n",
       "        0.96911463,  2.11772467,  1.71406262,  2.39110421,  1.52685412,\n",
       "        1.37886696,  0.30919488, -0.1957793 ,  0.12018822, -0.7097987 ,\n",
       "        0.0597169 , -0.89442082, -0.93263503,  0.33017866, -0.27868929,\n",
       "       -2.0759398 , -2.96015064, -1.53173759, -1.93993326, -0.12157232])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = Ridge()\n",
    "Y = train_rem['AVG(AvgTone)']\n",
    "X = train_rem[feature_columns_rem]\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(regr.score(X, Y))\n",
    "\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36msafe_sort\u001b[1;34m(values, labels, na_sentinel, assume_unique)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m             \u001b[0msorter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m             \u001b[0mordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-e5ed86fe2bc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdelt_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdelt_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mget_iterator\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1921\u001b[0m         \"\"\"\n\u001b[1;32m-> 1922\u001b[1;33m         \u001b[0msplitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_splitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_group_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_splitter\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1927\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_splitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1928\u001b[1;33m         \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1929\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_splitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.cache_readonly.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mgroup_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2038\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgroup_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m         \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_group_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_compressed_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_compressed_labels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_compressed_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m         \u001b[0mall_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mping\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             group_index = get_group_index(all_labels, self.shape,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_compressed_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m         \u001b[0mall_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mping\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             group_index = get_group_index(all_labels, self.shape,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mlabels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2748\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2750\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2751\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_make_labels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2765\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2766\u001b[0m                 labels, uniques = algorithms.factorize(\n\u001b[1;32m-> 2767\u001b[1;33m                     self.grouper, sort=self.sort)\n\u001b[0m\u001b[0;32m   2768\u001b[0m                 \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, order, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msafe_sort\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         uniques, labels = safe_sort(uniques, labels, na_sentinel=na_sentinel,\n\u001b[1;32m--> 479\u001b[1;33m                                     assume_unique=True)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36msafe_sort\u001b[1;34m(values, labels, na_sentinel, assume_unique)\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# try this anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             \u001b[0mordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort_mixed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[1;31m# labels:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36msort_mixed\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    434\u001b[0m         str_pos = np.array([isinstance(x, string_types) for x in values],\n\u001b[0;32m    435\u001b[0m                            dtype=bool)\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mstr_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mstrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "gdelt_sample.columns.to_series().groupby(gdelt_sample.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_sample = gdelt_sample.drop(['SQLDATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 218524 entries, 10869 to 2657273\n",
      "Columns: 196 entries, Actor1CountryCode to EventRootCode_20\n",
      "dtypes: category(9), float64(3), uint8(184)\n",
      "memory usage: 47.8 MB\n"
     ]
    }
   ],
   "source": [
    "gdelt_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_sample['Actor1CountryCode'].dtype == 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Actor2CountryCode', 'Actor1Geo_CountryCode', 'Actor2Geo_CountryCode',\n",
       "       'EventRootCode', 'AVG(NumMentions)', 'AVG(AvgTone)',\n",
       "       'Actor1CountryCode_unify', 'Actor2CountryCode_unify',\n",
       "       'Actor1Geo_CountryCode_unify', 'Actor2Geo_CountryCode_unify',\n",
       "       ...\n",
       "       'EventRootCode_11', 'EventRootCode_12', 'EventRootCode_13',\n",
       "       'EventRootCode_14', 'EventRootCode_15', 'EventRootCode_16',\n",
       "       'EventRootCode_17', 'EventRootCode_18', 'EventRootCode_19',\n",
       "       'EventRootCode_20'],\n",
       "      dtype='object', length=195)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt_sample.columns.drop(['Actor1CountryCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO reduce into quantile buckets\n",
    "def quantile_reduce(sample, column, pvalue, mag, count_penalty):\n",
    "    tones = sample['AVG(AvgTone)']\n",
    "    cntry = sample[column]\n",
    "\n",
    "    one_hot = pd.get_dummies(cntry)\n",
    "    one_hot_tone = pd.concat([tones, one_hot], axis=1)\n",
    "\n",
    "    avg_avgtone_mean = one_hot_tone['AVG(AvgTone)'].mean()\n",
    "\n",
    "    country_info = []\n",
    "    for column in one_hot.columns:\n",
    "        temp = one_hot_tone[[column, 'AVG(AvgTone)']]\n",
    "        country = temp[temp[column] == 1]\n",
    "        columns_mean = None\n",
    "        if len(country) < count_penalty: \n",
    "            column_means = [0, 0]\n",
    "            country_info.append((column, \n",
    "                                 0, \n",
    "                                 0, \n",
    "                                 (temp[column].sum()),\n",
    "                                 1)\n",
    "        else:\n",
    "            column_means = temp.groupby(column).mean()['AVG(AvgTone)']\n",
    "            country_info.append((column, \n",
    "                                 column_means[0] - column_means[1], \n",
    "                                 np.absolute(column_means[0] - column_means[1]), \n",
    "                                 (temp[column].sum()),\n",
    "                                 ttest_1samp(country, avg_avgtone_mean).pvalue[1]))\n",
    "\n",
    "    cntry_spec = pd.DataFrame(country_info, columns=[\"Country\", \"AvgTone_diff\", \"AvgTone_mag\", \"Num\", \"p-value\"])\n",
    "\n",
    "    low_decs = cntry_spec[((cntry_spec['p-value'] > pvalue) & ((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] < 0)))]['Country']\n",
    "\n",
    "    low_incs = cntry_spec[((cntry_spec['p-value'] > pvalue) & ((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] > 0)))]['Country']\n",
    "\n",
    "    low_p_value = cntry_spec[((cntry_spec['p-value'] > pvalue) & ~((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] < 0)) & ~((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] > 0)))]['Country']\n",
    "    \n",
    "    return low_decs, low_incs, low_p_value\n",
    "\n",
    "def map_quantile(x, low_decs, low_incs, low_p_value, translation):\n",
    "    if x == \"nan\":\n",
    "        return \"UNKNOWN\"\n",
    "    elif x in low_decs:\n",
    "        return \"LOW_DEC\"\n",
    "    elif x in low_incs:\n",
    "        return \"LOW_INCS\"\n",
    "    elif x in low_p_value:\n",
    "        return \"LOW_P_VALUE\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def unify_quantile_cats(data, category, pvalue, mag, low_decs, low_incs, low_p_value):\n",
    "    low_decs, low_incs, low_p_value = weak_reduce(data, category, pvalue, mag)\n",
    "    low_decs_unique = low_decs.unique()\n",
    "    low_decs_unique = low_incs.unique()\n",
    "    low_p_value_unique = low_p_value.unique()\n",
    "    data[(category + '_unify')] = data[category].astype(str) \\\n",
    "                                                .apply(lambda x: map_missing(x, low_decs_unique, \n",
    "                                                                             low_decs_unique, \n",
    "                                                                             low_p_value_unique, \n",
    "                                                                             \"OTHER\")) \\\n",
    "                                                .astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weak_reduce(sample, column, pvalue, mag, count_penalty):\n",
    "    tones = sample['AVG(AvgTone)']\n",
    "    cntry = sample[column]\n",
    "\n",
    "    one_hot = pd.get_dummies(cntry)\n",
    "    one_hot_tone = pd.concat([tones, one_hot], axis=1)\n",
    "\n",
    "    avg_avgtone_mean = one_hot_tone['AVG(AvgTone)'].mean()\n",
    "\n",
    "    country_info = []\n",
    "    for column in one_hot.columns:\n",
    "        temp = one_hot_tone[[column, 'AVG(AvgTone)']]\n",
    "        country = temp[temp[column] == 1]\n",
    "        columns_mean = None\n",
    "        if len(country) < count_penalty: \n",
    "            column_means = [0, 0]\n",
    "            country_info.append((column, \n",
    "                                 0, \n",
    "                                 0, \n",
    "                                 (temp[column].sum()),\n",
    "                                 1))\n",
    "        else:\n",
    "            column_means = temp.groupby(column).mean()['AVG(AvgTone)']\n",
    "            country_info.append((column, \n",
    "                                 column_means[0] - column_means[1], \n",
    "                                 np.absolute(column_means[0] - column_means[1]), \n",
    "                                 (temp[column].sum()),\n",
    "                                 ttest_1samp(country, avg_avgtone_mean).pvalue[1]))\n",
    "\n",
    "    cntry_spec = pd.DataFrame(country_info, columns=[\"Country\", \"AvgTone_diff\", \"AvgTone_mag\", \"Num\", \"p-value\"])\n",
    "\n",
    "    low_decs = cntry_spec[((cntry_spec['p-value'] > pvalue) & ((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] < 0)))]['Country']\n",
    "\n",
    "    low_incs = cntry_spec[((cntry_spec['p-value'] > pvalue) & ((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] > 0)))]['Country']\n",
    "\n",
    "    low_p_value = cntry_spec[((cntry_spec['p-value'] > pvalue) & ~((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] < 0)) & ~((cntry_spec['AvgTone_mag'] < mag) & \\\n",
    "               (cntry_spec['AvgTone_diff'] > 0)))]['Country']\n",
    "    \n",
    "    return low_decs, low_incs, low_p_value\n",
    "\n",
    "def map_weak(x, low_decs, low_incs, low_p_value, translation):\n",
    "    #if x in l:\n",
    "    #    return x\n",
    "    if x == \"nan\":\n",
    "        return \"UNKNOWN\"\n",
    "    elif x in low_decs:\n",
    "        return \"LOW_DEC\"\n",
    "    elif x in low_incs:\n",
    "        return \"LOW_INCS\"\n",
    "    elif x in low_p_value:\n",
    "        return \"LOW_P_VALUE\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def unify_weak_cats(data, category, pvalue, mag, count_penalty):\n",
    "    low_decs, low_incs, low_p_value = weak_reduce(data, category, pvalue, mag)\n",
    "    low_decs_unique = low_decs.unique()\n",
    "    low_decs_unique = low_incs.unique()\n",
    "    low_p_value_unique = low_p_value.unique()\n",
    "    data[(category + '_unify')] = data[category].astype(str) \\\n",
    "                                                .apply(lambda x: map_missing(x, low_decs_unique, \n",
    "                                                                             low_decs_unique, \n",
    "                                                                             low_p_value_unique, \n",
    "                                                                             \"OTHER\")) \\\n",
    "                                                .astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rare(x, l, translation):\n",
    "    if x in l:\n",
    "        return x\n",
    "    elif x == \"nan\":\n",
    "        return \"UNKNOWN\"\n",
    "    else:\n",
    "        return translation\n",
    "\n",
    "def unify_rare_cats(data, category, cut_off):\n",
    "    vc = data[category].value_counts()\n",
    "    past_cut_off = (vc/len(data)) > cut_off\n",
    "    remaining = list(vc[past_cut_off].index)\n",
    "    data[(category + '_unify')] = data[category].astype(str) \\\n",
    "                                                .apply(lambda x: map_rare(x, remaining, \"OTHER\")) \\\n",
    "                                                .astype('category')\n",
    "            \n",
    "def map_unknown(x):\n",
    "    if x == 'nan':\n",
    "        return \"UNKNOWN\"\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_sample(frac): \n",
    "    gdelt_sample = gdelt.sample(frac=frac) \\\n",
    "                        .drop(['SQLDATE'], axis=1)\n",
    "    gdelt_sample['norm_NumMentions'] = (gdelt_sample['AVG(NumMentions)'] \\\n",
    "                                                - gdelt_sample['AVG(NumMentions)'].mean())/ \\\n",
    "                                        gdelt_sample['AVG(NumMentions)'].std()\n",
    "    gdelt_sample = gdelt_sample.drop(['AVG(NumMentions)'], axis=1) \n",
    "    for category_col in gdelt_sample.columns:\n",
    "        if hasattr(live_samp[column], 'cat'):\n",
    "            gdelt_sample[category_col] = gdelt_sample[category_col] \\\n",
    "                                            .cat.remove_unused_categories()\n",
    "    return gdelt_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11',\n",
       " '04',\n",
       " '09',\n",
       " '05',\n",
       " '02',\n",
       " '19',\n",
       " '07',\n",
       " '10',\n",
       " '03',\n",
       " '18',\n",
       " '01',\n",
       " '13',\n",
       " '08',\n",
       " '12',\n",
       " '06',\n",
       " '14',\n",
       " '16',\n",
       " '17',\n",
       " '20',\n",
       " '15']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(init_sample(frac=.05)['EventRootCode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pare(sample):\n",
    "    return sample.drop(['Actor1Geo_CountryCode', 'Actor2Geo_CountryCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdelt_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-6b02f1da432f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdelt_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Actor1CountryCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gdelt_sample' is not defined"
     ]
    }
   ],
   "source": [
    "hasattr(gdelt_sample['Actor1CountryCode'], 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4495320082356185253"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.util.hash_pandas_object(test_samp).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"1\" in {\"2\": \"A\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {\"2\": \"a\"}\n",
    "test[\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Actor1CountryCode', 'Actor2CountryCode', 'Actor1Geo_CountryCode',\n",
       "       'Actor2Geo_CountryCode', 'EventRootCode', 'AVG(AvgTone)',\n",
       "       'norm_NumMentions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_cache = {}\n",
    "\n",
    "# https://github.com/pandas-dev/pandas/issues/8814\n",
    "def train_naive(sample, model):\n",
    "    h = pd.util.hash_pandas_object(sample).sum()\n",
    "    model_samp, feat_cols = None, None\n",
    "    if h not in naive_cache:\n",
    "        live_samp = sample.copy()\n",
    "\n",
    "        cat_dummies = []\n",
    "        drop_cols = []\n",
    "        for column in live_samp.columns:\n",
    "            if hasattr(live_samp[column], 'cat'):\n",
    "                live_samp[column] = live_samp[column].cat.add_categories(['UNK'])\n",
    "                live_samp[column].fillna('UNK')\n",
    "                hot = pd.get_dummies(live_samp[column], prefix=column)\n",
    "                cat_dummies.append(hot)\n",
    "                drop_cols.append(column)\n",
    "\n",
    "        live_samp = live_samp.drop(drop_cols, axis=1)            \n",
    "\n",
    "        one_hot_enc = pd.concat(cat_dummies, axis=1)\n",
    "\n",
    "        model_samp = pd.concat([live_samp, one_hot_enc], axis=1)\n",
    "        feat_cols = model_samp.columns.drop(['AVG(AvgTone)'])\n",
    "        \n",
    "        naive_cache[h] = (model_samp, feat_cols)\n",
    "    else:\n",
    "        model_samp, feat_cols = naive_cache[h]\n",
    "    \n",
    "    train, test = train_test_split(model_samp, test_size=0.25, random_state=42)\n",
    "    \n",
    "    Y = train['AVG(AvgTone)']\n",
    "    X = train[feat_cols]\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    train_score = model.score(X, Y)\n",
    "    Y_test = test['AVG(AvgTone)']\n",
    "    X_test = test[feat_cols]\n",
    "    test_score = model.score(X_test, Y_test)\n",
    "    \n",
    "    return train_score, test_score, model, model_samp, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pared_cache = {}\n",
    "\n",
    "def train_pared(sample, model):\n",
    "    h = pd.util.hash_pandas_object(sample).sum()\n",
    "    model_samp, feat_cols = None, None\n",
    "    if h not in pared_cache:\n",
    "        live_samp = sample.copy()\n",
    "        live_samp = pare(live_samp)\n",
    "\n",
    "        cat_dummies = []\n",
    "        drop_cols = []\n",
    "        for column in live_samp.columns:\n",
    "            if hasattr(live_samp[column], 'cat'):\n",
    "                hot = pd.get_dummies(live_samp[column], prefix=column)\n",
    "                cat_dummies.append(hot)\n",
    "                drop_cols.append(column)\n",
    "\n",
    "        live_samp = live_samp.drop(drop_cols, axis=1)            \n",
    "\n",
    "        one_hot_enc = pd.concat(cat_dummies, axis=1)\n",
    "\n",
    "        model_samp = pd.concat([live_samp, one_hot_enc], axis=1)\n",
    "        feat_cols = model_samp.columns.drop(['AVG(AvgTone)'])\n",
    "        \n",
    "        pared_cache[h] = (model_samp, feat_cols)\n",
    "    else:\n",
    "        model_samp, feat_cols = naive_cache[h]        \n",
    "\n",
    "    train, test = train_test_split(model_samp, test_size=0.25, random_state=42)\n",
    "    \n",
    "    Y = train['AVG(AvgTone)']\n",
    "    X = train[feat_cols]\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    train_score = model.score(X, Y)\n",
    "    Y_test = test['AVG(AvgTone)']\n",
    "    X_test = test[feat_cols]\n",
    "    test_score = model.score(X_test, Y_test)\n",
    "    \n",
    "    return train_score, test_score, model, model_samp, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_naive_URARE(sample, model, cut_off=.005):\n",
    "    live_samp = sample.copy()\n",
    "    \n",
    "    cat_dummies = []\n",
    "    drop_cols = []\n",
    "    for column in live_samp.columns:\n",
    "        if hasattr(live_samp[column], 'cat'):\n",
    "            unify_rare_cats(live_samp, column, cut_off)\n",
    "            hot = pd.get_dummies(live_samp[column], prefix=column)\n",
    "            cat_dummies.append(hot)\n",
    "            drop_cols.append(column)\n",
    "            \n",
    "    live_samp.drop(drop_cols, axis=1)            \n",
    "    \n",
    "    one_hot_enc = pd.concat(cat_dummies, axis=1)\n",
    "    \n",
    "    model_samp = pd.concat([live_samp, one_hot_enc])\n",
    "    feat_cols = model_samp.columns.drop(['AVG(AvgTone)'])\n",
    "    \n",
    "    train, test = train_test_split(live_samp, test_size=0.25, random_state=42)\n",
    "    \n",
    "    Y = train['AVG(AvgTone)']\n",
    "    X = train[feat_cols]\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    return train_score, test_score, model, model_samp, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_pared_URARE(sample, model, cut_off=.005):\n",
    "    live_samp = sample.copy()\n",
    "    live_samp = pare(live_samp)\n",
    "    \n",
    "    cat_dummies = []\n",
    "    drop_cols = []\n",
    "    for column in live_samp.columns:\n",
    "        if hasattr(live_samp[column], 'cat'):\n",
    "            unify_rare_cats(live_samp, column, cut_off)\n",
    "            hot = pd.get_dummies(live_samp[column], prefix=column)\n",
    "            cat_dummies.append(hot)\n",
    "            drop_cols.append(column)\n",
    "            \n",
    "    live_samp.drop(drop_cols, axis=1)            \n",
    "    \n",
    "    one_hot_enc = pd.concat(cat_dummies, axis=1)\n",
    "    \n",
    "    model_samp = pd.concat([live_samp, one_hot_enc])\n",
    "    feat_cols = model_samp.columns.drop(['AVG(AvgTone)'])\n",
    "    \n",
    "    train, test = train_test_split(live_samp, test_size=0.25, random_state=42)\n",
    "    \n",
    "    Y = train['AVG(AvgTone)']\n",
    "    X = train[feat_cols]\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    return train_score, test_score, model, model_samp, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_naive_UWEAK(sample, model, pvalue=0.0001, mag=1, count_penalty=10):\n",
    "    live_samp = sample.copy()\n",
    "    \n",
    "    cat_dummies = []\n",
    "    drop_cols = []\n",
    "    for column in live_samp.columns:\n",
    "        if hasattr(live_samp[column], 'cat'):\n",
    "            unify_weak_cats(live_samp, column, pvalue, mag, count_penalty)\n",
    "            hot = pd.get_dummies(live_samp[column], prefix=column)\n",
    "            cat_dummies.append(hot)\n",
    "            drop_cols.append(column)\n",
    "            \n",
    "    live_samp.drop(drop_cols, axis=1)            \n",
    "    \n",
    "    one_hot_enc = pd.concat(cat_dummies, axis=1)\n",
    "    \n",
    "    model_samp = pd.concat([live_samp, one_hot_enc])\n",
    "    feat_cols = model_samp.columns.drop(['AVG(AvgTone)'])\n",
    "    \n",
    "    train, test = train_test_split(live_samp, test_size=0.25, random_state=42)\n",
    "    \n",
    "    Y = train['AVG(AvgTone)']\n",
    "    X = train[feat_cols]\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    return train_score, test_score, model, model_samp, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_pared_UWEAK(sample, model, pvalue=0.0001, mag=1, count_penalty=10):\n",
    "    live_samp = sample.copy()\n",
    "    live_samp = pare(live_samp)\n",
    "        \n",
    "    cat_dummies = []\n",
    "    drop_cols = []\n",
    "    for column in live_samp.columns:\n",
    "        if hasattr(live_samp[column], 'cat'):\n",
    "            unify_weak_cats(live_samp, column, pvalue, mag, count_penalty)\n",
    "            hot = pd.get_dummies(live_samp[column], prefix=column)\n",
    "            cat_dummies.append(hot)\n",
    "            drop_cols.append(column)\n",
    "            \n",
    "    live_samp.drop(drop_cols, axis=1)            \n",
    "    \n",
    "    one_hot_enc = pd.concat(cat_dummies, axis=1)\n",
    "    \n",
    "    model_samp = pd.concat([live_samp, one_hot_enc])\n",
    "    feat_cols = model_samp.columns.drop(['AVG(AvgTone)'])\n",
    "    \n",
    "    train, test = train_test_split(live_samp, test_size=0.25, random_state=42)\n",
    "    \n",
    "    Y = train['AVG(AvgTone)']\n",
    "    X = train[feat_cols]\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    return train_score, test_score, model, model_samp, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can be used with pared and naive\n",
    "def ICM_INT_sample(sample, country):\n",
    "    cntry_sample = sample[sample['Actor1CountryCode'] == country].copy()\n",
    "    cntry_sample['InternalEvent?'] = (cntry_sample['Actor2CountryCode'] == country).astype(int)\n",
    "    cntry_sample = cntry_sample.drop(['Actor1CountryCode', 'Actor2CountryCode'], axis=1)\n",
    "    return cntry_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can be used with pared and naive\n",
    "def ICM_SPEC_sample(sample, country):\n",
    "    cntry_sample = sample[sample['Actor1CountryCode'] == country].copy()\n",
    "    cntry_sample = cntry_sample.drop(['Actor1CountryCode'], axis=1)\n",
    "    return cntry_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can only be used with naive\n",
    "def ICM_INT_GINT_sample(sample, country):\n",
    "    cntry_sample = sample[sample['Actor1CountryCode'] == country].copy()\n",
    "    cntry_sample['InternalEvent?'] = (cntry_sample['Actor2CountryCode'] != country).astype(int)\n",
    "    cntry_sample['Actor1AtHome?'] = (cntry_sample['Actor1Geo_CountryCode'] == country).astype(int)\n",
    "    cntry_sample['Actor2AtActor1Home?'] = (cntry_sample['Actor2Geo_CountryCode'] == country).astype(int)\n",
    "    cntry_sample = cntry_sample.drop(['Actor1CountryCode', 'Actor2CountryCode',\n",
    "                                     'Actor1Geo_CountryCode', 'Actor2Geo_CountryCode']\n",
    "                                     , axis=1)\n",
    "    return cntry_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can only be used with naive\n",
    "def ICM_INT_GSPEC_sample(sample, country):\n",
    "    cntry_sample = sample[sample['Actor1CountryCode'] == country].copy()\n",
    "    cntry_sample['InternalEvent?'] = (cntry_sample['Actor2CountryCode'] != country).astype(int)\n",
    "    cntry_sample['Actor2AtActor1Home?'] = (cntry_sample['Actor2Geo_CountryCode'] == country).astype(int)\n",
    "    cntry_sample = cntry_sample.drop(['Actor1CountryCode', 'Actor2CountryCode', \n",
    "                                      'Actor2Geo_CountryCode']\n",
    "                                     , axis=1)\n",
    "    return cntry_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can only be used with naive\n",
    "def ICM_FULL_sample(sample, country):\n",
    "    cntry_sample = sample[sample['Actor1CountryCode'] == country].copy()\n",
    "    cntry_sample = cntry_sample.drop(['Actor1CountryCode'], axis=1)\n",
    "    return cntry_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can only be used with naive\n",
    "def ICM_PERSPEC_sample(sample, country):\n",
    "    cntry_sample = sample[sample['Actor1CountryCode'] == country].copy()\n",
    "    cntry_sample['Actor1AtHome?'] = (cntry_sample['Actor1Geo_CountryCode'] == country).astype(int)\n",
    "    cntry_sample = cntry_sample.drop(['Actor1CountryCode', 'Actor1Geo_CountryCode']\n",
    "                                     , axis=1)\n",
    "    return cntry_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_samp = init_sample(.1)\n",
    "naive_samps = [#test_samp, \n",
    "               ICM_INT_sample(test_samp, 'USA'), ICM_SPEC_sample(test_samp, 'USA'),\n",
    "              ICM_INT_GINT_sample(test_samp, 'USA'), ICM_INT_GSPEC_sample(test_samp, 'USA'),\n",
    "              ICM_FULL_sample(test_samp, 'USA'), ICM_PERSPEC_sample(test_samp, 'USA')]\n",
    "pared_samps = [#test_samp, \n",
    "    ICM_INT_sample(test_samp, 'USA'), ICM_SPEC_sample(test_samp, 'USA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Actor1CountryCode', 'Actor2CountryCode', 'Actor1Geo_CountryCode',\n",
      "       'Actor2Geo_CountryCode', 'EventRootCode', 'AVG(AvgTone)',\n",
      "       'norm_NumMentions'],\n",
      "      dtype='object')\n",
      "Index(['Actor1Geo_CountryCode', 'Actor2Geo_CountryCode', 'EventRootCode',\n",
      "       'AVG(AvgTone)', 'norm_NumMentions', 'InternalEvent?'],\n",
      "      dtype='object')\n",
      "Index(['Actor2CountryCode', 'Actor1Geo_CountryCode', 'Actor2Geo_CountryCode',\n",
      "       'EventRootCode', 'AVG(AvgTone)', 'norm_NumMentions'],\n",
      "      dtype='object')\n",
      "Index(['EventRootCode', 'AVG(AvgTone)', 'norm_NumMentions', 'InternalEvent?',\n",
      "       'Actor1AtHome?', 'Actor2AtActor1Home?'],\n",
      "      dtype='object')\n",
      "Index(['Actor1Geo_CountryCode', 'EventRootCode', 'AVG(AvgTone)',\n",
      "       'norm_NumMentions', 'InternalEvent?', 'Actor2AtActor1Home?'],\n",
      "      dtype='object')\n",
      "Index(['Actor2CountryCode', 'Actor1Geo_CountryCode', 'Actor2Geo_CountryCode',\n",
      "       'EventRootCode', 'AVG(AvgTone)', 'norm_NumMentions'],\n",
      "      dtype='object')\n",
      "Index(['Actor2CountryCode', 'Actor2Geo_CountryCode', 'EventRootCode',\n",
      "       'AVG(AvgTone)', 'norm_NumMentions', 'Actor1AtHome?'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for samp in naive_samps:\n",
    "    print(samp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22298525152863793 -10229902.521455964\n",
      "1 0.2407581118726072 -252.84449704883204\n",
      "2 0.1440042942614571 0.14268231685292976\n",
      "3 0.1982143436425331 0.18045793529939902\n",
      "4 0.2407581118726072 -252.84449704883204\n",
      "5 0.21966379353406207 -393.6119756498297\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "regr = linear_model.LinearRegression()\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, regr)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22298525152863793 -10229902.521455964\n",
      "1 0.2407581118726072 -252.84449704883204\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "regr = linear_model.LinearRegression()\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, regr)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1783477185130503 0.13744424213990292\n",
      "1 0.18150919714717773 0.1321105668682423\n",
      "2 0.18892143167276432 0.09051210465680748\n",
      "3 0.174488908638749 0.13433565886537624\n",
      "4 0.18150919714717773 0.13322213520117399\n",
      "5 0.17852878272762285 0.13029809613095888\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "dt = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, dt)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1783477185130501 0.13692748295410295\n",
      "1 0.18150919714717773 0.13035444294080967\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "dt = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, dt)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1.0737730560495269 -1.0829197912427508\n",
      "[LibSVM]1 -0.4316803077223681 -0.4525066395461548\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-dd6fee05816c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnaive_samps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_samp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-249501493330>\u001b[0m in \u001b[0;36mtrain_naive\u001b[1;34m(sample, model)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AVG(AvgTone)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3823\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \u001b[1;34m\"\"\"same as values (but handles sparseness conversions)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3825\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3827\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mas_matrix\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mas_matrix\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m   3676\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3677\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3678\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3703\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3704\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3705\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3706\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "sv = svm.SVR()\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    sv = svm.SVR(max_iter=100, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, sv)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.8138925795679746 -0.8207373363354736\n",
      "[LibSVM]1 -0.9861201741513579 -1.014792952210204\n",
      "[LibSVM]2 -1.0181769044433375 -1.0469360329805206\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "sv = svm.SVR()\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    sv = svm.SVR(max_iter=100, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, sv)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15252194930074403 0.14014698136623127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.15372222301813332 0.13649468698567824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.15232871866673103 0.12718204489079854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.15214433079368583 0.13767346055927077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.15458167916781818 0.13656856934667994\n",
      "5 0.1534034299970254 0.13564947434752417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "rfc = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    rfc = RandomForestRegressor(max_depth=7, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, rfc)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15283755851648906 0.13396835274818775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.15337350943421746 0.13681772654912472\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "rfc = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    rfc = RandomForestRegressor(max_depth=7, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, rfc)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.18775209134502968 0.16907738989219456\n",
      "1 0.19098335477552275 0.17125714024711935\n",
      "2 0.14899043076301066 0.13957579670128462\n",
      "3 0.17873784549162963 0.1619455108127853\n",
      "4 0.19098335477552264 0.17124771660439264\n",
      "5 0.18633844748041128 0.16573886486655176\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.14899043076301066 0.13957579670128462\n",
      "1 0.17349904736707877 0.15816923373293024\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, gbr)\n",
    "    print(idx, trs, tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AVG(AvgTone)', 'norm_NumMentions', 'Actor2CountryCode_ABW',\n",
       "       'Actor2CountryCode_AFG', 'Actor2CountryCode_AFR',\n",
       "       'Actor2CountryCode_AGO', 'Actor2CountryCode_AIA',\n",
       "       'Actor2CountryCode_ALB', 'Actor2CountryCode_ARE',\n",
       "       'Actor2CountryCode_ARG',\n",
       "       ...\n",
       "       'EventRootCode_12', 'EventRootCode_13', 'EventRootCode_14',\n",
       "       'EventRootCode_15', 'EventRootCode_16', 'EventRootCode_17',\n",
       "       'EventRootCode_18', 'EventRootCode_19', 'EventRootCode_20',\n",
       "       'EventRootCode_--'],\n",
       "      dtype='object', length=243)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_samp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA    38097\n",
       "GBR    13437\n",
       "CHN    11355\n",
       "RUS    11321\n",
       "EUR     7938\n",
       "FRA     7930\n",
       "DEU     7368\n",
       "ISR     6470\n",
       "SAU     6189\n",
       "AUS     6095\n",
       "IRN     5759\n",
       "TUR     5737\n",
       "CAN     5630\n",
       "SYR     5051\n",
       "AFR     5002\n",
       "JPN     4606\n",
       "PAK     4363\n",
       "QAT     4127\n",
       "ITA     4102\n",
       "EGY     3709\n",
       "PRK     3543\n",
       "IND     3304\n",
       "KOR     3283\n",
       "PHL     3172\n",
       "IRQ     3166\n",
       "AFG     3068\n",
       "ESP     2860\n",
       "NGA     2819\n",
       "PSE     2793\n",
       "IRL     2721\n",
       "       ...  \n",
       "SAF       54\n",
       "GNB       48\n",
       "NRU       47\n",
       "CAS       45\n",
       "DMA       41\n",
       "KIR       40\n",
       "LIE       39\n",
       "SUR       38\n",
       "PLW       35\n",
       "FSM       34\n",
       "ABW       32\n",
       "COM       32\n",
       "CPV       32\n",
       "CRB       28\n",
       "MAC       24\n",
       "TUV       22\n",
       "AIA       22\n",
       "EAF       20\n",
       "STP       15\n",
       "GEO       13\n",
       "SMR        8\n",
       "SHN        6\n",
       "AND        2\n",
       "SAM        1\n",
       "WLF        1\n",
       "ROM        1\n",
       "SCN        1\n",
       "CAU        1\n",
       "LAM        0\n",
       "PRI        0\n",
       "Name: Actor1CountryCode, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samp['Actor1CountryCode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalIndex(['USA', 'GBR', 'CHN', 'RUS', 'EUR', 'FRA', 'DEU', 'ISR',\n",
       "                  'SAU', 'AUS',\n",
       "                  ...\n",
       "                  'SMR', 'SHN', 'AND', 'SAM', 'WLF', 'ROM', 'SCN', 'CAU',\n",
       "                  'LAM', 'PRI'],\n",
       "                 categories=['ABW', 'AFG', 'AFR', 'AGO', 'AIA', 'ALB', 'ARE', 'ARG', ...], ordered=False, dtype='category', length=221)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samp['Actor1CountryCode'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = list(test_samp['Actor1CountryCode'].value_counts().index)\n",
    "small_list = countries[:5]\n",
    "ICM_INT_samps = []\n",
    "ICM_SPEC_samps = []\n",
    "\n",
    "for country in small_list:\n",
    "    ICM_INT_samps.append(ICM_INT_sample(test_samp, country))\n",
    "    ICM_SPEC_samps.append(ICM_SPEC_sample(test_samp, country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NaN, JUD, GOV, CVL, MIL, ..., UIS, INT, SET, DEV, NGM]\n",
       "Length: 34\n",
       "Categories (33, object): [JUD, GOV, CVL, MIL, ..., INT, SET, DEV, NGM]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samp[\"Actor1Type1Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USA',\n",
       " 'GBR',\n",
       " 'RUS',\n",
       " 'CHN',\n",
       " 'FRA',\n",
       " 'ISR',\n",
       " 'DEU',\n",
       " 'AUS',\n",
       " 'CAN',\n",
       " 'EUR',\n",
       " 'TUR',\n",
       " 'SAU',\n",
       " 'PAK',\n",
       " 'IRN',\n",
       " 'IND',\n",
       " 'SYR',\n",
       " 'NGA',\n",
       " 'AFR',\n",
       " 'JPN',\n",
       " 'PHL',\n",
       " 'ITA',\n",
       " 'QAT',\n",
       " 'AFG',\n",
       " 'PRK',\n",
       " 'EGY',\n",
       " 'IRQ',\n",
       " 'KOR',\n",
       " 'PSE',\n",
       " 'IRL',\n",
       " 'ESP',\n",
       " 'MEX',\n",
       " 'MYS',\n",
       " 'UKR',\n",
       " 'JOR',\n",
       " 'IDN',\n",
       " 'ARE',\n",
       " 'BEL',\n",
       " 'POL',\n",
       " 'NZL',\n",
       " 'GRC',\n",
       " 'VNM',\n",
       " 'KEN',\n",
       " 'NLD',\n",
       " 'ZAF',\n",
       " 'CHE',\n",
       " 'GHA',\n",
       " 'THA',\n",
       " 'BGD',\n",
       " 'BRA',\n",
       " 'LBN',\n",
       " 'VEN',\n",
       " 'SGP',\n",
       " 'LBY',\n",
       " 'LKA',\n",
       " 'SWE',\n",
       " 'UGA',\n",
       " 'AZE',\n",
       " 'SDN',\n",
       " 'BHR',\n",
       " 'YEM',\n",
       " 'CUB',\n",
       " 'WST',\n",
       " 'ZWE',\n",
       " 'SOM',\n",
       " 'NOR',\n",
       " 'ARM',\n",
       " 'COL',\n",
       " 'TWN',\n",
       " 'SEA',\n",
       " 'DNK',\n",
       " 'MMR',\n",
       " 'PRT',\n",
       " 'AUT',\n",
       " 'HUN',\n",
       " 'MDV',\n",
       " 'VAT',\n",
       " 'KWT',\n",
       " 'KHM',\n",
       " 'BLR',\n",
       " 'ETH',\n",
       " 'JAM',\n",
       " 'SSD',\n",
       " 'KAZ',\n",
       " 'TZA',\n",
       " 'CZE',\n",
       " 'NPL',\n",
       " 'FIN',\n",
       " 'MAR',\n",
       " 'PAN',\n",
       " 'ARG',\n",
       " 'PER',\n",
       " 'ZMB',\n",
       " 'CYP',\n",
       " 'BGR',\n",
       " 'CHL',\n",
       " 'NMR',\n",
       " 'TUN',\n",
       " 'FJI',\n",
       " 'OMN',\n",
       " 'MCO',\n",
       " 'RWA',\n",
       " 'EST',\n",
       " 'MLT',\n",
       " 'LBR',\n",
       " 'LTU',\n",
       " 'BHS',\n",
       " 'DZA',\n",
       " 'ECU',\n",
       " 'TTO',\n",
       " 'MWI',\n",
       " 'MLI',\n",
       " 'GUY',\n",
       " 'TCD',\n",
       " 'COD',\n",
       " 'BLZ',\n",
       " 'HTI',\n",
       " 'LUX',\n",
       " 'LVA',\n",
       " 'HRV',\n",
       " 'UZB',\n",
       " 'NAM',\n",
       " 'NER',\n",
       " 'SRB',\n",
       " 'BWA',\n",
       " 'KGZ',\n",
       " 'GMB',\n",
       " 'MDA',\n",
       " 'GTM',\n",
       " 'CMR',\n",
       " 'SLV',\n",
       " 'AGO',\n",
       " 'BTN',\n",
       " 'ALB',\n",
       " 'BOL',\n",
       " 'MKD',\n",
       " 'TJK',\n",
       " 'BRN',\n",
       " 'SVK',\n",
       " 'CRI',\n",
       " 'COG',\n",
       " 'SEN',\n",
       " 'PNG',\n",
       " 'LAO',\n",
       " 'NIC',\n",
       " 'BRB',\n",
       " 'HND',\n",
       " 'SLE',\n",
       " 'ISL',\n",
       " 'TKM',\n",
       " 'BMU',\n",
       " 'SAS',\n",
       " 'DJI',\n",
       " 'DOM',\n",
       " 'MOZ',\n",
       " 'BDI',\n",
       " 'MUS',\n",
       " 'CIV',\n",
       " 'CAF',\n",
       " 'BEN',\n",
       " 'ERI',\n",
       " 'GRD',\n",
       " 'GIN',\n",
       " 'MNG',\n",
       " 'WSM',\n",
       " 'PGS',\n",
       " 'LCA',\n",
       " 'LSO',\n",
       " 'VCT',\n",
       " 'BFA',\n",
       " 'URY',\n",
       " 'CYM',\n",
       " 'MDG',\n",
       " 'PRY',\n",
       " 'SWZ',\n",
       " 'MRT',\n",
       " 'KNA',\n",
       " 'SLB',\n",
       " 'WAF',\n",
       " 'VUT',\n",
       " 'TON',\n",
       " 'SYC',\n",
       " 'ATG',\n",
       " 'TGO',\n",
       " 'MHL',\n",
       " 'ASA',\n",
       " 'MEA',\n",
       " 'HKG',\n",
       " 'TMP',\n",
       " 'GAB',\n",
       " 'COK',\n",
       " 'GNQ',\n",
       " 'SAF',\n",
       " 'GNB',\n",
       " 'DMA',\n",
       " 'NRU',\n",
       " 'LIE',\n",
       " 'CPV',\n",
       " 'KIR',\n",
       " 'CAS',\n",
       " 'SUR',\n",
       " 'ABW',\n",
       " 'COM',\n",
       " 'AIA',\n",
       " 'CRB',\n",
       " 'FSM',\n",
       " 'TUV',\n",
       " 'PLW',\n",
       " 'MAC',\n",
       " 'EAF',\n",
       " 'STP',\n",
       " 'SMR',\n",
       " 'GEO',\n",
       " 'SHN',\n",
       " 'AND',\n",
       " 'LAM',\n",
       " 'SAM',\n",
       " 'SCN',\n",
       " 'WLF',\n",
       " 'PRI',\n",
       " 'ROM',\n",
       " 'CAU']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.24333228325996237 0.2262816802125384\n",
      "1 0.24965027613334156 0.23185156875762714\n",
      "2 0.17856855337558952 0.15920843211098767\n",
      "3 0.21444089481469716 0.18064178662407737\n",
      "4 0.21027126052482337 0.1438042799111917\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "model_samp = None\n",
    "for idx, samp in enumerate(ICM_INT_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG(AvgTone)',\n",
       " 'norm_NumMentions',\n",
       " 'InternalEvent?',\n",
       " 'Actor1Type1Code_AGR',\n",
       " 'Actor1Type1Code_BUS',\n",
       " 'Actor1Type1Code_COP',\n",
       " 'Actor1Type1Code_CRM',\n",
       " 'Actor1Type1Code_CVL',\n",
       " 'Actor1Type1Code_EDU',\n",
       " 'Actor1Type1Code_ELI',\n",
       " 'Actor1Type1Code_ENV',\n",
       " 'Actor1Type1Code_GOV',\n",
       " 'Actor1Type1Code_HLH',\n",
       " 'Actor1Type1Code_HRI',\n",
       " 'Actor1Type1Code_IGO',\n",
       " 'Actor1Type1Code_IMG',\n",
       " 'Actor1Type1Code_INS',\n",
       " 'Actor1Type1Code_INT',\n",
       " 'Actor1Type1Code_JUD',\n",
       " 'Actor1Type1Code_LAB',\n",
       " 'Actor1Type1Code_LEG',\n",
       " 'Actor1Type1Code_MED',\n",
       " 'Actor1Type1Code_MIL',\n",
       " 'Actor1Type1Code_MNC',\n",
       " 'Actor1Type1Code_NGM',\n",
       " 'Actor1Type1Code_NGO',\n",
       " 'Actor1Type1Code_OPP',\n",
       " 'Actor1Type1Code_RAD',\n",
       " 'Actor1Type1Code_REB',\n",
       " 'Actor1Type1Code_REF',\n",
       " 'Actor1Type1Code_SEP',\n",
       " 'Actor1Type1Code_SET',\n",
       " 'Actor1Type1Code_SPY',\n",
       " 'Actor1Type1Code_UAF',\n",
       " 'Actor1Type1Code_UIS',\n",
       " 'Actor1Type1Code_DEV',\n",
       " 'Actor1Type1Code_UNK',\n",
       " 'Actor2Type1Code_AGR',\n",
       " 'Actor2Type1Code_BUS',\n",
       " 'Actor2Type1Code_COP',\n",
       " 'Actor2Type1Code_CRM',\n",
       " 'Actor2Type1Code_CVL',\n",
       " 'Actor2Type1Code_EDU',\n",
       " 'Actor2Type1Code_ELI',\n",
       " 'Actor2Type1Code_ENV',\n",
       " 'Actor2Type1Code_GOV',\n",
       " 'Actor2Type1Code_HLH',\n",
       " 'Actor2Type1Code_HRI',\n",
       " 'Actor2Type1Code_IGO',\n",
       " 'Actor2Type1Code_IMG',\n",
       " 'Actor2Type1Code_INS',\n",
       " 'Actor2Type1Code_INT',\n",
       " 'Actor2Type1Code_JUD',\n",
       " 'Actor2Type1Code_LAB',\n",
       " 'Actor2Type1Code_LEG',\n",
       " 'Actor2Type1Code_MED',\n",
       " 'Actor2Type1Code_MIL',\n",
       " 'Actor2Type1Code_MNC',\n",
       " 'Actor2Type1Code_NGM',\n",
       " 'Actor2Type1Code_NGO',\n",
       " 'Actor2Type1Code_OPP',\n",
       " 'Actor2Type1Code_RAD',\n",
       " 'Actor2Type1Code_REB',\n",
       " 'Actor2Type1Code_REF',\n",
       " 'Actor2Type1Code_SEP',\n",
       " 'Actor2Type1Code_SET',\n",
       " 'Actor2Type1Code_SPY',\n",
       " 'Actor2Type1Code_UAF',\n",
       " 'Actor2Type1Code_UIS',\n",
       " 'Actor2Type1Code_DEV',\n",
       " 'Actor2Type1Code_UNK',\n",
       " 'Actor1Geo_CountryCode_AA',\n",
       " 'Actor1Geo_CountryCode_AC',\n",
       " 'Actor1Geo_CountryCode_AE',\n",
       " 'Actor1Geo_CountryCode_AF',\n",
       " 'Actor1Geo_CountryCode_AG',\n",
       " 'Actor1Geo_CountryCode_AJ',\n",
       " 'Actor1Geo_CountryCode_AL',\n",
       " 'Actor1Geo_CountryCode_AM',\n",
       " 'Actor1Geo_CountryCode_AO',\n",
       " 'Actor1Geo_CountryCode_AR',\n",
       " 'Actor1Geo_CountryCode_AS',\n",
       " 'Actor1Geo_CountryCode_AU',\n",
       " 'Actor1Geo_CountryCode_AV',\n",
       " 'Actor1Geo_CountryCode_AY',\n",
       " 'Actor1Geo_CountryCode_BA',\n",
       " 'Actor1Geo_CountryCode_BB',\n",
       " 'Actor1Geo_CountryCode_BC',\n",
       " 'Actor1Geo_CountryCode_BD',\n",
       " 'Actor1Geo_CountryCode_BE',\n",
       " 'Actor1Geo_CountryCode_BF',\n",
       " 'Actor1Geo_CountryCode_BG',\n",
       " 'Actor1Geo_CountryCode_BH',\n",
       " 'Actor1Geo_CountryCode_BK',\n",
       " 'Actor1Geo_CountryCode_BL',\n",
       " 'Actor1Geo_CountryCode_BM',\n",
       " 'Actor1Geo_CountryCode_BN',\n",
       " 'Actor1Geo_CountryCode_BO',\n",
       " 'Actor1Geo_CountryCode_BP',\n",
       " 'Actor1Geo_CountryCode_BR',\n",
       " 'Actor1Geo_CountryCode_BT',\n",
       " 'Actor1Geo_CountryCode_BU',\n",
       " 'Actor1Geo_CountryCode_BX',\n",
       " 'Actor1Geo_CountryCode_BY',\n",
       " 'Actor1Geo_CountryCode_CA',\n",
       " 'Actor1Geo_CountryCode_CB',\n",
       " 'Actor1Geo_CountryCode_CD',\n",
       " 'Actor1Geo_CountryCode_CE',\n",
       " 'Actor1Geo_CountryCode_CF',\n",
       " 'Actor1Geo_CountryCode_CG',\n",
       " 'Actor1Geo_CountryCode_CH',\n",
       " 'Actor1Geo_CountryCode_CI',\n",
       " 'Actor1Geo_CountryCode_CJ',\n",
       " 'Actor1Geo_CountryCode_CM',\n",
       " 'Actor1Geo_CountryCode_CN',\n",
       " 'Actor1Geo_CountryCode_CO',\n",
       " 'Actor1Geo_CountryCode_CQ',\n",
       " 'Actor1Geo_CountryCode_CS',\n",
       " 'Actor1Geo_CountryCode_CT',\n",
       " 'Actor1Geo_CountryCode_CU',\n",
       " 'Actor1Geo_CountryCode_CV',\n",
       " 'Actor1Geo_CountryCode_CW',\n",
       " 'Actor1Geo_CountryCode_CY',\n",
       " 'Actor1Geo_CountryCode_DA',\n",
       " 'Actor1Geo_CountryCode_DJ',\n",
       " 'Actor1Geo_CountryCode_DO',\n",
       " 'Actor1Geo_CountryCode_DR',\n",
       " 'Actor1Geo_CountryCode_EC',\n",
       " 'Actor1Geo_CountryCode_EG',\n",
       " 'Actor1Geo_CountryCode_EI',\n",
       " 'Actor1Geo_CountryCode_EK',\n",
       " 'Actor1Geo_CountryCode_EN',\n",
       " 'Actor1Geo_CountryCode_ER',\n",
       " 'Actor1Geo_CountryCode_ES',\n",
       " 'Actor1Geo_CountryCode_ET',\n",
       " 'Actor1Geo_CountryCode_EZ',\n",
       " 'Actor1Geo_CountryCode_FG',\n",
       " 'Actor1Geo_CountryCode_FI',\n",
       " 'Actor1Geo_CountryCode_FJ',\n",
       " 'Actor1Geo_CountryCode_FM',\n",
       " 'Actor1Geo_CountryCode_FP',\n",
       " 'Actor1Geo_CountryCode_FR',\n",
       " 'Actor1Geo_CountryCode_GA',\n",
       " 'Actor1Geo_CountryCode_GB',\n",
       " 'Actor1Geo_CountryCode_GG',\n",
       " 'Actor1Geo_CountryCode_GH',\n",
       " 'Actor1Geo_CountryCode_GI',\n",
       " 'Actor1Geo_CountryCode_GJ',\n",
       " 'Actor1Geo_CountryCode_GK',\n",
       " 'Actor1Geo_CountryCode_GL',\n",
       " 'Actor1Geo_CountryCode_GM',\n",
       " 'Actor1Geo_CountryCode_GQ',\n",
       " 'Actor1Geo_CountryCode_GR',\n",
       " 'Actor1Geo_CountryCode_GT',\n",
       " 'Actor1Geo_CountryCode_GV',\n",
       " 'Actor1Geo_CountryCode_GY',\n",
       " 'Actor1Geo_CountryCode_GZ',\n",
       " 'Actor1Geo_CountryCode_HA',\n",
       " 'Actor1Geo_CountryCode_HK',\n",
       " 'Actor1Geo_CountryCode_HO',\n",
       " 'Actor1Geo_CountryCode_HR',\n",
       " 'Actor1Geo_CountryCode_HU',\n",
       " 'Actor1Geo_CountryCode_IC',\n",
       " 'Actor1Geo_CountryCode_ID',\n",
       " 'Actor1Geo_CountryCode_IN',\n",
       " 'Actor1Geo_CountryCode_IR',\n",
       " 'Actor1Geo_CountryCode_IS',\n",
       " 'Actor1Geo_CountryCode_IT',\n",
       " 'Actor1Geo_CountryCode_IV',\n",
       " 'Actor1Geo_CountryCode_IZ',\n",
       " 'Actor1Geo_CountryCode_JA',\n",
       " 'Actor1Geo_CountryCode_JE',\n",
       " 'Actor1Geo_CountryCode_JM',\n",
       " 'Actor1Geo_CountryCode_JO',\n",
       " 'Actor1Geo_CountryCode_KE',\n",
       " 'Actor1Geo_CountryCode_KG',\n",
       " 'Actor1Geo_CountryCode_KN',\n",
       " 'Actor1Geo_CountryCode_KR',\n",
       " 'Actor1Geo_CountryCode_KS',\n",
       " 'Actor1Geo_CountryCode_KT',\n",
       " 'Actor1Geo_CountryCode_KU',\n",
       " 'Actor1Geo_CountryCode_KV',\n",
       " 'Actor1Geo_CountryCode_KZ',\n",
       " 'Actor1Geo_CountryCode_LA',\n",
       " 'Actor1Geo_CountryCode_LE',\n",
       " 'Actor1Geo_CountryCode_LG',\n",
       " 'Actor1Geo_CountryCode_LH',\n",
       " 'Actor1Geo_CountryCode_LI',\n",
       " 'Actor1Geo_CountryCode_LO',\n",
       " 'Actor1Geo_CountryCode_LT',\n",
       " 'Actor1Geo_CountryCode_LU',\n",
       " 'Actor1Geo_CountryCode_LY',\n",
       " 'Actor1Geo_CountryCode_MA',\n",
       " 'Actor1Geo_CountryCode_MB',\n",
       " 'Actor1Geo_CountryCode_MC',\n",
       " 'Actor1Geo_CountryCode_MD',\n",
       " 'Actor1Geo_CountryCode_MG',\n",
       " 'Actor1Geo_CountryCode_MH',\n",
       " 'Actor1Geo_CountryCode_MI',\n",
       " 'Actor1Geo_CountryCode_MJ',\n",
       " 'Actor1Geo_CountryCode_MK',\n",
       " 'Actor1Geo_CountryCode_ML',\n",
       " 'Actor1Geo_CountryCode_MN',\n",
       " 'Actor1Geo_CountryCode_MO',\n",
       " 'Actor1Geo_CountryCode_MP',\n",
       " 'Actor1Geo_CountryCode_MR',\n",
       " 'Actor1Geo_CountryCode_MT',\n",
       " 'Actor1Geo_CountryCode_MU',\n",
       " 'Actor1Geo_CountryCode_MV',\n",
       " 'Actor1Geo_CountryCode_MX',\n",
       " 'Actor1Geo_CountryCode_MY',\n",
       " 'Actor1Geo_CountryCode_MZ',\n",
       " 'Actor1Geo_CountryCode_NC',\n",
       " 'Actor1Geo_CountryCode_NE',\n",
       " 'Actor1Geo_CountryCode_NG',\n",
       " 'Actor1Geo_CountryCode_NH',\n",
       " 'Actor1Geo_CountryCode_NI',\n",
       " 'Actor1Geo_CountryCode_NL',\n",
       " 'Actor1Geo_CountryCode_NO',\n",
       " 'Actor1Geo_CountryCode_NP',\n",
       " 'Actor1Geo_CountryCode_NR',\n",
       " 'Actor1Geo_CountryCode_NS',\n",
       " 'Actor1Geo_CountryCode_NU',\n",
       " 'Actor1Geo_CountryCode_NZ',\n",
       " 'Actor1Geo_CountryCode_OC',\n",
       " 'Actor1Geo_CountryCode_OD',\n",
       " 'Actor1Geo_CountryCode_OS',\n",
       " 'Actor1Geo_CountryCode_PA',\n",
       " 'Actor1Geo_CountryCode_PE',\n",
       " 'Actor1Geo_CountryCode_PK',\n",
       " 'Actor1Geo_CountryCode_PL',\n",
       " 'Actor1Geo_CountryCode_PM',\n",
       " 'Actor1Geo_CountryCode_PO',\n",
       " 'Actor1Geo_CountryCode_PP',\n",
       " 'Actor1Geo_CountryCode_PS',\n",
       " 'Actor1Geo_CountryCode_QA',\n",
       " 'Actor1Geo_CountryCode_RB',\n",
       " 'Actor1Geo_CountryCode_RE',\n",
       " 'Actor1Geo_CountryCode_RI',\n",
       " 'Actor1Geo_CountryCode_RM',\n",
       " 'Actor1Geo_CountryCode_RN',\n",
       " 'Actor1Geo_CountryCode_RO',\n",
       " 'Actor1Geo_CountryCode_RP',\n",
       " 'Actor1Geo_CountryCode_RQ',\n",
       " 'Actor1Geo_CountryCode_RS',\n",
       " 'Actor1Geo_CountryCode_RW',\n",
       " 'Actor1Geo_CountryCode_SA',\n",
       " 'Actor1Geo_CountryCode_SC',\n",
       " 'Actor1Geo_CountryCode_SE',\n",
       " 'Actor1Geo_CountryCode_SF',\n",
       " 'Actor1Geo_CountryCode_SG',\n",
       " 'Actor1Geo_CountryCode_SI',\n",
       " 'Actor1Geo_CountryCode_SL',\n",
       " 'Actor1Geo_CountryCode_SM',\n",
       " 'Actor1Geo_CountryCode_SN',\n",
       " 'Actor1Geo_CountryCode_SO',\n",
       " 'Actor1Geo_CountryCode_SP',\n",
       " 'Actor1Geo_CountryCode_ST',\n",
       " 'Actor1Geo_CountryCode_SU',\n",
       " 'Actor1Geo_CountryCode_SW',\n",
       " 'Actor1Geo_CountryCode_SY',\n",
       " 'Actor1Geo_CountryCode_SZ',\n",
       " 'Actor1Geo_CountryCode_TD',\n",
       " 'Actor1Geo_CountryCode_TH',\n",
       " 'Actor1Geo_CountryCode_TI',\n",
       " 'Actor1Geo_CountryCode_TK',\n",
       " 'Actor1Geo_CountryCode_TN',\n",
       " 'Actor1Geo_CountryCode_TS',\n",
       " 'Actor1Geo_CountryCode_TT',\n",
       " 'Actor1Geo_CountryCode_TU',\n",
       " 'Actor1Geo_CountryCode_TW',\n",
       " 'Actor1Geo_CountryCode_TX',\n",
       " 'Actor1Geo_CountryCode_TZ',\n",
       " 'Actor1Geo_CountryCode_UG',\n",
       " 'Actor1Geo_CountryCode_UK',\n",
       " 'Actor1Geo_CountryCode_UP',\n",
       " 'Actor1Geo_CountryCode_US',\n",
       " 'Actor1Geo_CountryCode_UV',\n",
       " 'Actor1Geo_CountryCode_UY',\n",
       " 'Actor1Geo_CountryCode_UZ',\n",
       " 'Actor1Geo_CountryCode_VC',\n",
       " 'Actor1Geo_CountryCode_VE',\n",
       " 'Actor1Geo_CountryCode_VI',\n",
       " 'Actor1Geo_CountryCode_VM',\n",
       " 'Actor1Geo_CountryCode_VQ',\n",
       " 'Actor1Geo_CountryCode_VT',\n",
       " 'Actor1Geo_CountryCode_WA',\n",
       " 'Actor1Geo_CountryCode_WE',\n",
       " 'Actor1Geo_CountryCode_WI',\n",
       " 'Actor1Geo_CountryCode_WS',\n",
       " 'Actor1Geo_CountryCode_WZ',\n",
       " 'Actor1Geo_CountryCode_YM',\n",
       " 'Actor1Geo_CountryCode_ZA',\n",
       " 'Actor1Geo_CountryCode_ZI',\n",
       " 'Actor1Geo_CountryCode_AQ',\n",
       " 'Actor1Geo_CountryCode_GP',\n",
       " 'Actor1Geo_CountryCode_LS',\n",
       " 'Actor1Geo_CountryCode_PU',\n",
       " 'Actor1Geo_CountryCode_TO',\n",
       " 'Actor1Geo_CountryCode_TV',\n",
       " 'Actor1Geo_CountryCode_FK',\n",
       " 'Actor1Geo_CountryCode_FO',\n",
       " 'Actor1Geo_CountryCode_NT',\n",
       " 'Actor1Geo_CountryCode_SV',\n",
       " 'Actor1Geo_CountryCode_SH',\n",
       " 'Actor1Geo_CountryCode_TL',\n",
       " 'Actor1Geo_CountryCode_YI',\n",
       " 'Actor1Geo_CountryCode_IO',\n",
       " 'Actor1Geo_CountryCode_AN',\n",
       " 'Actor1Geo_CountryCode_SB',\n",
       " 'Actor1Geo_CountryCode_TP',\n",
       " 'Actor1Geo_CountryCode_IM',\n",
       " 'Actor1Geo_CountryCode_PC',\n",
       " 'Actor1Geo_CountryCode_MF',\n",
       " 'Actor1Geo_CountryCode_PG',\n",
       " 'Actor1Geo_CountryCode_WQ',\n",
       " 'Actor1Geo_CountryCode_NF',\n",
       " 'Actor1Geo_CountryCode_JN',\n",
       " 'Actor1Geo_CountryCode_JQ',\n",
       " 'Actor1Geo_CountryCode_PF',\n",
       " 'Actor1Geo_CountryCode_HQ',\n",
       " 'Actor1Geo_CountryCode_DQ',\n",
       " 'Actor1Geo_CountryCode_KQ',\n",
       " 'Actor1Geo_CountryCode_CR',\n",
       " 'Actor1Geo_CountryCode_IP',\n",
       " 'Actor1Geo_CountryCode_FQ',\n",
       " 'Actor1Geo_CountryCode_LQ',\n",
       " 'Actor1Geo_CountryCode_UNK',\n",
       " 'Actor2Geo_CountryCode_AA',\n",
       " 'Actor2Geo_CountryCode_AC',\n",
       " 'Actor2Geo_CountryCode_AE',\n",
       " 'Actor2Geo_CountryCode_AF',\n",
       " 'Actor2Geo_CountryCode_AG',\n",
       " 'Actor2Geo_CountryCode_AJ',\n",
       " 'Actor2Geo_CountryCode_AL',\n",
       " 'Actor2Geo_CountryCode_AM',\n",
       " 'Actor2Geo_CountryCode_AO',\n",
       " 'Actor2Geo_CountryCode_AQ',\n",
       " 'Actor2Geo_CountryCode_AR',\n",
       " 'Actor2Geo_CountryCode_AS',\n",
       " 'Actor2Geo_CountryCode_AU',\n",
       " 'Actor2Geo_CountryCode_AY',\n",
       " 'Actor2Geo_CountryCode_BA',\n",
       " 'Actor2Geo_CountryCode_BB',\n",
       " 'Actor2Geo_CountryCode_BC',\n",
       " 'Actor2Geo_CountryCode_BD',\n",
       " 'Actor2Geo_CountryCode_BE',\n",
       " 'Actor2Geo_CountryCode_BF',\n",
       " 'Actor2Geo_CountryCode_BG',\n",
       " 'Actor2Geo_CountryCode_BH',\n",
       " 'Actor2Geo_CountryCode_BK',\n",
       " 'Actor2Geo_CountryCode_BL',\n",
       " 'Actor2Geo_CountryCode_BM',\n",
       " 'Actor2Geo_CountryCode_BN',\n",
       " 'Actor2Geo_CountryCode_BO',\n",
       " 'Actor2Geo_CountryCode_BP',\n",
       " 'Actor2Geo_CountryCode_BR',\n",
       " 'Actor2Geo_CountryCode_BT',\n",
       " 'Actor2Geo_CountryCode_BU',\n",
       " 'Actor2Geo_CountryCode_BX',\n",
       " 'Actor2Geo_CountryCode_BY',\n",
       " 'Actor2Geo_CountryCode_CA',\n",
       " 'Actor2Geo_CountryCode_CB',\n",
       " 'Actor2Geo_CountryCode_CD',\n",
       " 'Actor2Geo_CountryCode_CE',\n",
       " 'Actor2Geo_CountryCode_CF',\n",
       " 'Actor2Geo_CountryCode_CG',\n",
       " 'Actor2Geo_CountryCode_CH',\n",
       " 'Actor2Geo_CountryCode_CI',\n",
       " 'Actor2Geo_CountryCode_CJ',\n",
       " 'Actor2Geo_CountryCode_CM',\n",
       " 'Actor2Geo_CountryCode_CN',\n",
       " 'Actor2Geo_CountryCode_CO',\n",
       " 'Actor2Geo_CountryCode_CQ',\n",
       " 'Actor2Geo_CountryCode_CS',\n",
       " 'Actor2Geo_CountryCode_CT',\n",
       " 'Actor2Geo_CountryCode_CU',\n",
       " 'Actor2Geo_CountryCode_CV',\n",
       " 'Actor2Geo_CountryCode_CW',\n",
       " 'Actor2Geo_CountryCode_CY',\n",
       " 'Actor2Geo_CountryCode_DA',\n",
       " 'Actor2Geo_CountryCode_DJ',\n",
       " 'Actor2Geo_CountryCode_DO',\n",
       " 'Actor2Geo_CountryCode_DR',\n",
       " 'Actor2Geo_CountryCode_EC',\n",
       " 'Actor2Geo_CountryCode_EG',\n",
       " 'Actor2Geo_CountryCode_EI',\n",
       " 'Actor2Geo_CountryCode_EK',\n",
       " 'Actor2Geo_CountryCode_EN',\n",
       " 'Actor2Geo_CountryCode_ER',\n",
       " 'Actor2Geo_CountryCode_ES',\n",
       " 'Actor2Geo_CountryCode_ET',\n",
       " 'Actor2Geo_CountryCode_EZ',\n",
       " 'Actor2Geo_CountryCode_FI',\n",
       " 'Actor2Geo_CountryCode_FJ',\n",
       " 'Actor2Geo_CountryCode_FM',\n",
       " 'Actor2Geo_CountryCode_FP',\n",
       " 'Actor2Geo_CountryCode_FR',\n",
       " 'Actor2Geo_CountryCode_GA',\n",
       " 'Actor2Geo_CountryCode_GG',\n",
       " 'Actor2Geo_CountryCode_GH',\n",
       " 'Actor2Geo_CountryCode_GI',\n",
       " 'Actor2Geo_CountryCode_GJ',\n",
       " 'Actor2Geo_CountryCode_GK',\n",
       " 'Actor2Geo_CountryCode_GL',\n",
       " 'Actor2Geo_CountryCode_GM',\n",
       " 'Actor2Geo_CountryCode_GQ',\n",
       " 'Actor2Geo_CountryCode_GR',\n",
       " 'Actor2Geo_CountryCode_GT',\n",
       " 'Actor2Geo_CountryCode_GV',\n",
       " 'Actor2Geo_CountryCode_GY',\n",
       " 'Actor2Geo_CountryCode_GZ',\n",
       " 'Actor2Geo_CountryCode_HA',\n",
       " 'Actor2Geo_CountryCode_HK',\n",
       " 'Actor2Geo_CountryCode_HO',\n",
       " 'Actor2Geo_CountryCode_HR',\n",
       " 'Actor2Geo_CountryCode_HU',\n",
       " 'Actor2Geo_CountryCode_IC',\n",
       " 'Actor2Geo_CountryCode_ID',\n",
       " 'Actor2Geo_CountryCode_IN',\n",
       " 'Actor2Geo_CountryCode_IR',\n",
       " 'Actor2Geo_CountryCode_IS',\n",
       " 'Actor2Geo_CountryCode_IT',\n",
       " 'Actor2Geo_CountryCode_IV',\n",
       " 'Actor2Geo_CountryCode_IZ',\n",
       " 'Actor2Geo_CountryCode_JA',\n",
       " 'Actor2Geo_CountryCode_JE',\n",
       " 'Actor2Geo_CountryCode_JM',\n",
       " 'Actor2Geo_CountryCode_JO',\n",
       " 'Actor2Geo_CountryCode_KE',\n",
       " 'Actor2Geo_CountryCode_KG',\n",
       " 'Actor2Geo_CountryCode_KN',\n",
       " 'Actor2Geo_CountryCode_KR',\n",
       " 'Actor2Geo_CountryCode_KS',\n",
       " 'Actor2Geo_CountryCode_KT',\n",
       " 'Actor2Geo_CountryCode_KU',\n",
       " 'Actor2Geo_CountryCode_KV',\n",
       " 'Actor2Geo_CountryCode_KZ',\n",
       " 'Actor2Geo_CountryCode_LA',\n",
       " 'Actor2Geo_CountryCode_LE',\n",
       " 'Actor2Geo_CountryCode_LG',\n",
       " 'Actor2Geo_CountryCode_LH',\n",
       " 'Actor2Geo_CountryCode_LI',\n",
       " 'Actor2Geo_CountryCode_LO',\n",
       " 'Actor2Geo_CountryCode_LT',\n",
       " 'Actor2Geo_CountryCode_LU',\n",
       " 'Actor2Geo_CountryCode_LY',\n",
       " 'Actor2Geo_CountryCode_MA',\n",
       " 'Actor2Geo_CountryCode_MB',\n",
       " 'Actor2Geo_CountryCode_MC',\n",
       " 'Actor2Geo_CountryCode_MD',\n",
       " 'Actor2Geo_CountryCode_MF',\n",
       " 'Actor2Geo_CountryCode_MG',\n",
       " 'Actor2Geo_CountryCode_MI',\n",
       " 'Actor2Geo_CountryCode_MJ',\n",
       " 'Actor2Geo_CountryCode_MK',\n",
       " 'Actor2Geo_CountryCode_ML',\n",
       " 'Actor2Geo_CountryCode_MN',\n",
       " 'Actor2Geo_CountryCode_MO',\n",
       " 'Actor2Geo_CountryCode_MP',\n",
       " 'Actor2Geo_CountryCode_MR',\n",
       " 'Actor2Geo_CountryCode_MT',\n",
       " 'Actor2Geo_CountryCode_MU',\n",
       " 'Actor2Geo_CountryCode_MV',\n",
       " 'Actor2Geo_CountryCode_MX',\n",
       " 'Actor2Geo_CountryCode_MY',\n",
       " 'Actor2Geo_CountryCode_MZ',\n",
       " 'Actor2Geo_CountryCode_NC',\n",
       " 'Actor2Geo_CountryCode_NE',\n",
       " 'Actor2Geo_CountryCode_NG',\n",
       " 'Actor2Geo_CountryCode_NH',\n",
       " 'Actor2Geo_CountryCode_NI',\n",
       " 'Actor2Geo_CountryCode_NL',\n",
       " 'Actor2Geo_CountryCode_NO',\n",
       " 'Actor2Geo_CountryCode_NP',\n",
       " 'Actor2Geo_CountryCode_NR',\n",
       " 'Actor2Geo_CountryCode_NS',\n",
       " 'Actor2Geo_CountryCode_NU',\n",
       " 'Actor2Geo_CountryCode_NZ',\n",
       " 'Actor2Geo_CountryCode_OC',\n",
       " 'Actor2Geo_CountryCode_OD',\n",
       " 'Actor2Geo_CountryCode_OS',\n",
       " 'Actor2Geo_CountryCode_PA',\n",
       " 'Actor2Geo_CountryCode_PE',\n",
       " 'Actor2Geo_CountryCode_PK',\n",
       " 'Actor2Geo_CountryCode_PL',\n",
       " 'Actor2Geo_CountryCode_PM',\n",
       " 'Actor2Geo_CountryCode_PO',\n",
       " 'Actor2Geo_CountryCode_PP',\n",
       " 'Actor2Geo_CountryCode_PS',\n",
       " 'Actor2Geo_CountryCode_QA',\n",
       " 'Actor2Geo_CountryCode_RB',\n",
       " 'Actor2Geo_CountryCode_RE',\n",
       " 'Actor2Geo_CountryCode_RI',\n",
       " 'Actor2Geo_CountryCode_RM',\n",
       " 'Actor2Geo_CountryCode_RO',\n",
       " 'Actor2Geo_CountryCode_RP',\n",
       " 'Actor2Geo_CountryCode_RQ',\n",
       " 'Actor2Geo_CountryCode_RS',\n",
       " 'Actor2Geo_CountryCode_RW',\n",
       " 'Actor2Geo_CountryCode_SA',\n",
       " 'Actor2Geo_CountryCode_SC',\n",
       " 'Actor2Geo_CountryCode_SE',\n",
       " 'Actor2Geo_CountryCode_SF',\n",
       " 'Actor2Geo_CountryCode_SG',\n",
       " 'Actor2Geo_CountryCode_SI',\n",
       " 'Actor2Geo_CountryCode_SL',\n",
       " 'Actor2Geo_CountryCode_SM',\n",
       " 'Actor2Geo_CountryCode_SN',\n",
       " 'Actor2Geo_CountryCode_SO',\n",
       " 'Actor2Geo_CountryCode_SP',\n",
       " 'Actor2Geo_CountryCode_ST',\n",
       " 'Actor2Geo_CountryCode_SU',\n",
       " 'Actor2Geo_CountryCode_SW',\n",
       " 'Actor2Geo_CountryCode_SY',\n",
       " 'Actor2Geo_CountryCode_SZ',\n",
       " 'Actor2Geo_CountryCode_TD',\n",
       " 'Actor2Geo_CountryCode_TH',\n",
       " 'Actor2Geo_CountryCode_TI',\n",
       " 'Actor2Geo_CountryCode_TK',\n",
       " 'Actor2Geo_CountryCode_TN',\n",
       " 'Actor2Geo_CountryCode_TO',\n",
       " 'Actor2Geo_CountryCode_TS',\n",
       " 'Actor2Geo_CountryCode_TT',\n",
       " 'Actor2Geo_CountryCode_TU',\n",
       " 'Actor2Geo_CountryCode_TW',\n",
       " 'Actor2Geo_CountryCode_TX',\n",
       " 'Actor2Geo_CountryCode_TZ',\n",
       " 'Actor2Geo_CountryCode_UG',\n",
       " 'Actor2Geo_CountryCode_UK',\n",
       " 'Actor2Geo_CountryCode_UP',\n",
       " 'Actor2Geo_CountryCode_US',\n",
       " 'Actor2Geo_CountryCode_UV',\n",
       " 'Actor2Geo_CountryCode_UY',\n",
       " 'Actor2Geo_CountryCode_UZ',\n",
       " 'Actor2Geo_CountryCode_VC',\n",
       " 'Actor2Geo_CountryCode_VE',\n",
       " 'Actor2Geo_CountryCode_VI',\n",
       " 'Actor2Geo_CountryCode_VM',\n",
       " 'Actor2Geo_CountryCode_VQ',\n",
       " 'Actor2Geo_CountryCode_VT',\n",
       " 'Actor2Geo_CountryCode_WA',\n",
       " 'Actor2Geo_CountryCode_WE',\n",
       " 'Actor2Geo_CountryCode_WI',\n",
       " 'Actor2Geo_CountryCode_WS',\n",
       " 'Actor2Geo_CountryCode_WZ',\n",
       " 'Actor2Geo_CountryCode_YI',\n",
       " 'Actor2Geo_CountryCode_YM',\n",
       " 'Actor2Geo_CountryCode_ZA',\n",
       " 'Actor2Geo_CountryCode_ZI',\n",
       " 'Actor2Geo_CountryCode_AV',\n",
       " 'Actor2Geo_CountryCode_FG',\n",
       " 'Actor2Geo_CountryCode_GB',\n",
       " 'Actor2Geo_CountryCode_GP',\n",
       " 'Actor2Geo_CountryCode_LS',\n",
       " 'Actor2Geo_CountryCode_MH',\n",
       " 'Actor2Geo_CountryCode_PU',\n",
       " 'Actor2Geo_CountryCode_RN',\n",
       " 'Actor2Geo_CountryCode_SV',\n",
       " 'Actor2Geo_CountryCode_TV',\n",
       " 'Actor2Geo_CountryCode_FK',\n",
       " 'Actor2Geo_CountryCode_FO',\n",
       " 'Actor2Geo_CountryCode_NT',\n",
       " 'Actor2Geo_CountryCode_IO',\n",
       " 'Actor2Geo_CountryCode_SH',\n",
       " 'Actor2Geo_CountryCode_AN',\n",
       " 'Actor2Geo_CountryCode_TL',\n",
       " 'Actor2Geo_CountryCode_SB',\n",
       " 'Actor2Geo_CountryCode_TP',\n",
       " 'Actor2Geo_CountryCode_IM',\n",
       " 'Actor2Geo_CountryCode_WQ',\n",
       " 'Actor2Geo_CountryCode_PC',\n",
       " 'Actor2Geo_CountryCode_PG',\n",
       " 'Actor2Geo_CountryCode_PF',\n",
       " 'Actor2Geo_CountryCode_NF',\n",
       " 'Actor2Geo_CountryCode_JN',\n",
       " 'Actor2Geo_CountryCode_JQ',\n",
       " 'Actor2Geo_CountryCode_HQ',\n",
       " 'Actor2Geo_CountryCode_FQ',\n",
       " 'Actor2Geo_CountryCode_LQ',\n",
       " 'Actor2Geo_CountryCode_UNK',\n",
       " 'EventRootCode_01',\n",
       " 'EventRootCode_02',\n",
       " 'EventRootCode_03',\n",
       " 'EventRootCode_04',\n",
       " 'EventRootCode_05',\n",
       " 'EventRootCode_06',\n",
       " 'EventRootCode_07',\n",
       " 'EventRootCode_08',\n",
       " 'EventRootCode_09',\n",
       " 'EventRootCode_10',\n",
       " 'EventRootCode_11',\n",
       " 'EventRootCode_12',\n",
       " 'EventRootCode_13',\n",
       " 'EventRootCode_14',\n",
       " 'EventRootCode_15',\n",
       " 'EventRootCode_16',\n",
       " 'EventRootCode_17',\n",
       " 'EventRootCode_18',\n",
       " 'EventRootCode_19',\n",
       " 'EventRootCode_20',\n",
       " 'EventRootCode_UNK']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_samp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.24500311564020785 0.22657179470550767\n",
      "1 0.2529619848337147 0.23385525482250447\n",
      "2 0.1857721200897093 0.16578582041024548\n",
      "3 0.22260619485121225 0.18980500556437396\n",
      "4 0.21680215723307228 0.1446967095226489\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(ICM_SPEC_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def country_info(sample, column, pvalue, mag, count_penalty):\n",
    "    tones = sample['AVG(AvgTone)']\n",
    "    cntry = sample[column]\n",
    "\n",
    "    one_hot = pd.get_dummies(cntry)\n",
    "    one_hot_tone = pd.concat([tones, one_hot], axis=1)\n",
    "\n",
    "    avg_avgtone_mean = one_hot_tone['AVG(AvgTone)'].mean()\n",
    "\n",
    "    country_info = []\n",
    "    for column in one_hot.columns:\n",
    "        temp = one_hot_tone[[column, 'AVG(AvgTone)']]\n",
    "        country = temp[temp[column] == 1]\n",
    "        columns_mean = None\n",
    "        if len(country) < count_penalty: \n",
    "            column_means = [0, 0]\n",
    "            country_info.append((column, \n",
    "                                 0, \n",
    "                                 0, \n",
    "                                 (temp[column].sum()),\n",
    "                                 1))\n",
    "        else:\n",
    "            column_means = temp.groupby(column).mean()['AVG(AvgTone)']\n",
    "            country_info.append((column, \n",
    "                                 column_means[0] - column_means[1], \n",
    "                                 np.absolute(column_means[0] - column_means[1]), \n",
    "                                 (temp[column].sum()),\n",
    "                                 ttest_1samp(country, avg_avgtone_mean).pvalue[1]))\n",
    "\n",
    "    cntry_spec = pd.DataFrame(country_info, columns=[\"Country\", \"AvgTone_diff\", \"AvgTone_mag\", \"Num\", \"p-value\"])\n",
    "    \n",
    "    return cntry_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cntry_info = country_info(test_samp, 'Actor1CountryCode', .001, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>AvgTone_diff</th>\n",
       "      <th>AvgTone_mag</th>\n",
       "      <th>Num</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>VEN</td>\n",
       "      <td>2.895562</td>\n",
       "      <td>2.895562</td>\n",
       "      <td>1886</td>\n",
       "      <td>4.489826e-202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>SSD</td>\n",
       "      <td>2.195552</td>\n",
       "      <td>2.195552</td>\n",
       "      <td>1068</td>\n",
       "      <td>1.624059e-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>FIN</td>\n",
       "      <td>-2.026532</td>\n",
       "      <td>2.026532</td>\n",
       "      <td>1008</td>\n",
       "      <td>2.936085e-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>VNM</td>\n",
       "      <td>-1.884847</td>\n",
       "      <td>1.884847</td>\n",
       "      <td>2636</td>\n",
       "      <td>1.339151e-136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>YEM</td>\n",
       "      <td>1.811866</td>\n",
       "      <td>1.811866</td>\n",
       "      <td>1631</td>\n",
       "      <td>1.144110e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NZL</td>\n",
       "      <td>-1.807352</td>\n",
       "      <td>1.807352</td>\n",
       "      <td>2650</td>\n",
       "      <td>2.530839e-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>LBY</td>\n",
       "      <td>1.783420</td>\n",
       "      <td>1.783420</td>\n",
       "      <td>1831</td>\n",
       "      <td>1.618481e-123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BLR</td>\n",
       "      <td>-1.779256</td>\n",
       "      <td>1.779256</td>\n",
       "      <td>1109</td>\n",
       "      <td>5.773632e-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>PSE</td>\n",
       "      <td>1.772175</td>\n",
       "      <td>1.772175</td>\n",
       "      <td>4322</td>\n",
       "      <td>1.063865e-198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>SGP</td>\n",
       "      <td>-1.771658</td>\n",
       "      <td>1.771658</td>\n",
       "      <td>1870</td>\n",
       "      <td>3.116748e-94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>SYR</td>\n",
       "      <td>1.734355</td>\n",
       "      <td>1.734355</td>\n",
       "      <td>7157</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>TWN</td>\n",
       "      <td>-1.709884</td>\n",
       "      <td>1.709884</td>\n",
       "      <td>1347</td>\n",
       "      <td>8.405353e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>SOM</td>\n",
       "      <td>1.663543</td>\n",
       "      <td>1.663543</td>\n",
       "      <td>1574</td>\n",
       "      <td>1.189997e-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>KAZ</td>\n",
       "      <td>-1.660536</td>\n",
       "      <td>1.660536</td>\n",
       "      <td>1067</td>\n",
       "      <td>4.477455e-61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GHA</td>\n",
       "      <td>-1.584149</td>\n",
       "      <td>1.584149</td>\n",
       "      <td>2313</td>\n",
       "      <td>1.810316e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1.579120</td>\n",
       "      <td>1.579120</td>\n",
       "      <td>4894</td>\n",
       "      <td>1.857452e-176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DNK</td>\n",
       "      <td>-1.339783</td>\n",
       "      <td>1.339783</td>\n",
       "      <td>1258</td>\n",
       "      <td>1.217923e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>SDN</td>\n",
       "      <td>1.318032</td>\n",
       "      <td>1.318032</td>\n",
       "      <td>1658</td>\n",
       "      <td>6.637413e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>IRQ</td>\n",
       "      <td>1.305562</td>\n",
       "      <td>1.305562</td>\n",
       "      <td>4569</td>\n",
       "      <td>4.075359e-156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>JPN</td>\n",
       "      <td>-1.297688</td>\n",
       "      <td>1.297688</td>\n",
       "      <td>6295</td>\n",
       "      <td>1.832100e-197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>NOR</td>\n",
       "      <td>-1.256414</td>\n",
       "      <td>1.256414</td>\n",
       "      <td>1450</td>\n",
       "      <td>4.247157e-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NLD</td>\n",
       "      <td>-1.210315</td>\n",
       "      <td>1.210315</td>\n",
       "      <td>2546</td>\n",
       "      <td>1.064358e-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CHE</td>\n",
       "      <td>-1.178787</td>\n",
       "      <td>1.178787</td>\n",
       "      <td>2427</td>\n",
       "      <td>7.229023e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CZE</td>\n",
       "      <td>-1.129414</td>\n",
       "      <td>1.129414</td>\n",
       "      <td>1045</td>\n",
       "      <td>8.081689e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARM</td>\n",
       "      <td>-1.119027</td>\n",
       "      <td>1.119027</td>\n",
       "      <td>1428</td>\n",
       "      <td>6.422185e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CHN</td>\n",
       "      <td>-1.116166</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>16061</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>IRN</td>\n",
       "      <td>1.064493</td>\n",
       "      <td>1.064493</td>\n",
       "      <td>7819</td>\n",
       "      <td>3.476606e-185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>VAT</td>\n",
       "      <td>-1.061016</td>\n",
       "      <td>1.061016</td>\n",
       "      <td>1165</td>\n",
       "      <td>1.295413e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>PRK</td>\n",
       "      <td>1.043152</td>\n",
       "      <td>1.043152</td>\n",
       "      <td>4863</td>\n",
       "      <td>7.798404e-185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>LBN</td>\n",
       "      <td>1.039933</td>\n",
       "      <td>1.039933</td>\n",
       "      <td>1973</td>\n",
       "      <td>6.733498e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>MLT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>656</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>MNG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>MOZ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>278</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>MRT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>MUS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>274</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>MWI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>579</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NAM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>462</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NER</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>445</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NIC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>347</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>LVA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>498</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>LUX</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>511</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>LTU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>607</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>HND</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GIN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GMB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>433</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>GNQ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>GRD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>GTM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>425</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>GUY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>577</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>HKG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>HRV</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>480</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>LCA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>209</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>HTI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>518</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ISL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>303</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>KGZ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>437</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KIR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>KNA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>LAO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>349</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>LBR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>625</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>CAU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country  AvgTone_diff  AvgTone_mag    Num        p-value\n",
       "198     VEN      2.895562     2.895562   1886  4.489826e-202\n",
       "170     SSD      2.195552     2.195552   1068   1.624059e-72\n",
       "63      FIN     -2.026532     2.026532   1008   2.936085e-71\n",
       "199     VNM     -1.884847     1.884847   2636  1.339151e-136\n",
       "204     YEM      1.811866     1.811866   1631   1.144110e-83\n",
       "138     NZL     -1.807352     1.807352   2650  2.530839e-154\n",
       "104     LBY      1.783420     1.783420   1831  1.618481e-123\n",
       "21      BLR     -1.779256     1.779256   1109   5.773632e-60\n",
       "151     PSE      1.772175     1.772175   4322  1.063865e-198\n",
       "163     SGP     -1.771658     1.771658   1870   3.116748e-94\n",
       "177     SYR      1.734355     1.734355   7157   0.000000e+00\n",
       "189     TWN     -1.709884     1.709884   1347   8.405353e-67\n",
       "168     SOM      1.663543     1.663543   1574   1.189997e-62\n",
       "93      KAZ     -1.660536     1.660536   1067   4.477455e-61\n",
       "69      GHA     -1.584149     1.584149   2313   1.810316e-78\n",
       "1       AFG      1.579120     1.579120   4894  1.857452e-176\n",
       "52      DNK     -1.339783     1.339783   1258   1.217923e-34\n",
       "160     SDN      1.318032     1.318032   1658   6.637413e-51\n",
       "86      IRQ      1.305562     1.305562   4569  4.075359e-156\n",
       "92      JPN     -1.297688     1.297688   6295  1.832100e-197\n",
       "135     NOR     -1.256414     1.256414   1450   4.247157e-39\n",
       "133     NLD     -1.210315     1.210315   2546   1.064358e-64\n",
       "32      CHE     -1.178787     1.178787   2427   7.229023e-54\n",
       "48      CZE     -1.129414     1.129414   1045   8.081689e-24\n",
       "7       ARM     -1.119027     1.119027   1428   6.422185e-24\n",
       "34      CHN     -1.116166     1.116166  16061   0.000000e+00\n",
       "85      IRN      1.064493     1.064493   7819  3.476606e-185\n",
       "196     VAT     -1.061016     1.061016   1165   1.295413e-35\n",
       "148     PRK      1.043152     1.043152   4863  7.798404e-185\n",
       "102     LBN      1.039933     1.039933   1973   6.733498e-29\n",
       "..      ...           ...          ...    ...            ...\n",
       "121     MLT      0.000000     0.000000    656   1.000000e+00\n",
       "123     MNG      0.000000     0.000000    234   1.000000e+00\n",
       "124     MOZ      0.000000     0.000000    278   1.000000e+00\n",
       "125     MRT      0.000000     0.000000    140   1.000000e+00\n",
       "126     MUS      0.000000     0.000000    274   1.000000e+00\n",
       "127     MWI      0.000000     0.000000    579   1.000000e+00\n",
       "129     NAM      0.000000     0.000000    462   1.000000e+00\n",
       "130     NER      0.000000     0.000000    445   1.000000e+00\n",
       "132     NIC      0.000000     0.000000    347   1.000000e+00\n",
       "109     LVA      0.000000     0.000000    498   1.000000e+00\n",
       "108     LUX      0.000000     0.000000    511   1.000000e+00\n",
       "107     LTU      0.000000     0.000000    607   1.000000e+00\n",
       "78      HND      0.000000     0.000000    316   1.000000e+00\n",
       "70      GIN      0.000000     0.000000    240   1.000000e+00\n",
       "71      GMB      0.000000     0.000000    433   1.000000e+00\n",
       "72      GNQ      0.000000     0.000000     70   1.000000e+00\n",
       "74      GRD      0.000000     0.000000    250   1.000000e+00\n",
       "75      GTM      0.000000     0.000000    425   1.000000e+00\n",
       "76      GUY      0.000000     0.000000    577   1.000000e+00\n",
       "77      HKG      0.000000     0.000000     84   1.000000e+00\n",
       "79      HRV      0.000000     0.000000    480   1.000000e+00\n",
       "105     LCA      0.000000     0.000000    209   1.000000e+00\n",
       "80      HTI      0.000000     0.000000    518   1.000000e+00\n",
       "87      ISL      0.000000     0.000000    303   1.000000e+00\n",
       "95      KGZ      0.000000     0.000000    437   1.000000e+00\n",
       "97      KIR      0.000000     0.000000     44   1.000000e+00\n",
       "98      KNA      0.000000     0.000000    127   1.000000e+00\n",
       "101     LAO      0.000000     0.000000    349   1.000000e+00\n",
       "103     LBR      0.000000     0.000000    625   1.000000e+00\n",
       "220     CAU      0.000000     0.000000      0   1.000000e+00\n",
       "\n",
       "[221 rows x 5 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cntry_info.sort_values(by=\"AvgTone_mag\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_mag = cntry_info.sort_values(by=\"AvgTone_mag\", ascending=False)['Country'].iloc[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ICM_INT_samps = []\n",
    "ICM_SPEC_samps = []\n",
    "\n",
    "for country in high_mag:\n",
    "    ICM_INT_samps.append(ICM_INT_sample(test_samp, country))\n",
    "    ICM_SPEC_samps.append(ICM_SPEC_sample(test_samp, country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.38755695126036005 0.19258362032559118\n",
      "1 0.35593512198977695 0.07819305199186188\n",
      "2 0.3886114118911289 0.16646019635859388\n",
      "3 0.3489402000564874 0.28924872953878444\n",
      "4 0.3460912158167547 0.10566933784584799\n",
      "5 0.3022041056302651 0.07750937949119319\n",
      "6 0.2742283496523297 0.13862907501102684\n",
      "7 0.4341013268499114 0.17203490598634838\n",
      "8 0.3445674903014083 0.26128010222859055\n",
      "9 0.3488075650757112 0.1425286999661225\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(ICM_INT_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.64748657e-05, 4.14429217e-05,\n",
       "       9.62372493e-05, 1.43365713e-04, 3.32905540e-04, 7.44458684e-04,\n",
       "       9.42322631e-04, 9.58518453e-04, 1.01504063e-03, 1.02707248e-03,\n",
       "       1.02727099e-03, 1.05694154e-03, 1.06285061e-03, 1.06639860e-03,\n",
       "       1.52300726e-03, 1.52723072e-03, 1.75607514e-03, 1.78261413e-03,\n",
       "       1.89185352e-03, 2.26589002e-03, 2.67193881e-03, 2.78351121e-03,\n",
       "       2.92046758e-03, 2.98870607e-03, 3.25733485e-03, 3.82563331e-03,\n",
       "       4.12104033e-03, 4.13222281e-03, 4.25177498e-03, 4.65063686e-03,\n",
       "       4.82510060e-03, 4.86280524e-03, 5.26707870e-03, 5.37540879e-03,\n",
       "       5.58000580e-03, 5.60409821e-03, 5.70533097e-03, 6.26484294e-03,\n",
       "       6.46584042e-03, 6.53108243e-03, 6.60038410e-03, 6.61154415e-03,\n",
       "       7.71668697e-03, 7.78685307e-03, 7.80292402e-03, 7.88314497e-03,\n",
       "       8.40703278e-03, 8.66288702e-03, 8.73423794e-03, 9.21659004e-03,\n",
       "       9.28742972e-03, 9.64417211e-03, 1.02667097e-02, 1.04345322e-02,\n",
       "       1.05984393e-02, 1.07288661e-02, 1.07324087e-02, 1.10467469e-02,\n",
       "       1.19251313e-02, 1.19676713e-02, 1.20803873e-02, 1.21356728e-02,\n",
       "       1.22354551e-02, 1.24621635e-02, 1.26573298e-02, 1.31409896e-02,\n",
       "       1.36854779e-02, 1.49824138e-02, 1.53875177e-02, 1.64782097e-02,\n",
       "       1.70254024e-02, 1.70508807e-02, 1.74348416e-02, 1.80665106e-02,\n",
       "       1.95873022e-02, 1.97715126e-02, 2.12084363e-02, 2.22729560e-02,\n",
       "       2.38421710e-02, 2.56593825e-02, 2.85671251e-02, 3.21765262e-02,\n",
       "       3.28464142e-02, 3.36161794e-02, 3.38430547e-02, 3.69253004e-02,\n",
       "       4.72539957e-02, 4.99414376e-02, 6.92377287e-02])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.39212680046226167 0.11400759684024053\n",
      "1 0.3370976096876699 0.07571608692342457\n",
      "2 0.3481733162458482 0.14329152666508904\n",
      "3 0.19959829018828878 0.07966490031154527\n",
      "4 0.3674671210299214 0.2282376459634341\n",
      "5 0.38584929886402664 0.15874273199721145\n",
      "6 0.44001384582061615 0.2575568333114048\n",
      "7 0.3814017455169927 0.2114692143538751\n",
      "8 0.38897428095868425 0.15943424925519145\n",
      "9 0.3288651711964845 0.11736104563768956\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(ICM_SPEC_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive - Actor1CC, Actor2CC, Actor1GCC, Actor2GCC, EventRootCode, NumMentions\n",
    "pared - Actor1CC, Actor2CC, EventRootCode, NumMentions\n",
    "\n",
    "w/o infrequent columns naive \n",
    "w/o infrequent columns pared\n",
    "\n",
    "w/o low effect countries naive \n",
    "w/o low effect countries pared\n",
    "\n",
    "pared ICM-INT - individualized country models for Actor1CC - Actor2CC international or not\n",
    "pared ICM-SPEC - individualized country models for Actor1CC - Actor2CC maintains value\n",
    "\n",
    "naive ICM-INT/ICM-SPEC - as before but with Actor1GCC and Actor2GCC unchanged\n",
    "naive ICM-INT-INT - both Actor1GCC/Actor2GCC code internal or international\n",
    "naive ICM-INT-SPEC - Actor1GCC maintains location of Actor1, Actor2GCC codes international\n",
    "\n",
    "Actor2AtActor1Home vs Actor2AtHome\n",
    "\n",
    "quantile buckets countries naive\n",
    "quantile buckets countries pared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
