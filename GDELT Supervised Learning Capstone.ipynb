{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.base import clone\n",
    "%matplotlib inline\n",
    "\n",
    "from GDELT_utils import dtype_dict_for_tone, \\\n",
    "                        init_sample, ICM_INT_sample, ICM_SPEC_sample, \\\n",
    "                        train_naive, train_pared, \\\n",
    "                        train_pared_URARE, train_pared_UWEAK, country_info, \\\n",
    "                        map_rare, unify_rare_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt = pd.read_csv(\"gdelt_agg_big.csv\",\n",
    "                    dtype=dtype_dict_for_tone,\n",
    "                   parse_dates=[\"SQLDATE\"])\n",
    "gdelt = gdelt.drop(labels=gdelt[(gdelt['EventRootCode'] == \"--\")].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_samp = gdelt.sample(frac=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report we're going to take a look at the data from the Global Data on Events, Location and Tone project, also known as GDELT. GDELT provides data on global events, storing such things as the type of the event, the actors involved, the location and the tone of documents that report on the event. It thus provides an abstract and data driven view of the world's affairs. It has been in operation since 2013, and has data available from January 1, 1979 to the present. For our sample of the data, we're focusing on a relatively arbitrary three month period of 2017 from May 1 to August 1.\n",
    "\n",
    "Our focus will be on building predictive models of the AvgTone information provided in the GDELT dataset. This column aggregates the average tone of the documents talking about the event which has been recorded in the data. This can give an overall tone of the narrative that has developed around an event. We will find that the relationships are highly non-linear and that decision trees and derived ensemble models based on them perform well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns from the GDELT dataset that we have are focused on for building our models in addition to AvgTone are \"SQLDATE\", \"EventRootCode\", \"NumMentions\", \"Actor1CountryCode\", \"Actor1Type1Code\", \"Actor1Geo_CountryCode\", as well as these latter \"Actor1\" prefixed columns also having an \"Actor2\" variant. For the purposes of modeling, the mean of AvgTone was taken across records with the same \"SQLDATE\", \"Actor1CountryCode\", \"Actor2CountryCode\", \"Actor1Type1Code\", \"Actor2Type1Code\", \"Actor1Geo_CountryCode\", \"Actor2Geo_CountryCode\", and \"EventRootCode\". \"NumMentions\" was also averaged in this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actor codes (except for the Geo fields) and EventRootCodes are encoded in the CAMEO code system. CAMEO codes capture the concept of \"two actors and the action performed by Actor1 upon Actor2.\" An overview of CAMEO codes can be found at [this link](https://www.gdeltproject.org/data/documentation/CAMEO.Manual.1.1b3.pdf). \n",
    "\n",
    "A brief description of the data columns follows, while a more exhaustive description can be found in the [GDELT Data Format Documentation](http://data.gdeltproject.org/documentation/GDELT-Data_Format_Codebook.pdf).\n",
    "* SQLDATE is an iso-encoded year, month and day. \n",
    "* EventRootCode is the root of the CAMEO code encoding the event. This is a very coarse understanding of the CAMEO event, indicating broad \"verbs\" of the action performed by Actor1 upon Actor2 like: \"Make Public Statement\", \"Appeal\", \"Demand\", \"Disapprove\", \"Protest\", \"Fight\", etc. Generally as the number increases, the verb indicates increasing degrees of aggression and violence, with 01 being \"Make a Public Statement\" and 20 being \"Engage in Unconventional Mass Violence.\"\n",
    "* Actor1CountryCode (Actor2CountryCode) codes the country affiliation of Actor1 (Actor2) as encoded in the CAMEO system.\n",
    "* Actor1Type1Code (Actor2Type1Code) codes the \"type\" or \"role\" of Actor1 (Actor2). This can be something specific such as \"Police Forces\" or more broad such as \"Refugees\" or \"Media\". \n",
    "* Actor1Geo_CountryCode (Actor2Geo_CountryCode) is an addition to the CAMEO system which encodes the location of Actor1 (Actor2) when performing the action.\n",
    "* NumMentions is the total number of mentions of the event across all source documents including multiple references within the same document. This can be used as a rough approximation of the \"importance\" and \"scale\" of an event.\n",
    "* AvgTone is the average \"tone\" of all documents containing one or more mentions of this event. The scores range from -100 (extremely negative) to +100 (extremely positive) while most values are between -10 and 10. This can also give a sense of the \"impact\" of an event, e.g. a riot with a small negative average tone is likely a minor occurrence, whereas with one with a large negative average tone is a more serious one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQLDATE</th>\n",
       "      <th>Actor1CountryCode</th>\n",
       "      <th>Actor2CountryCode</th>\n",
       "      <th>Actor1Type1Code</th>\n",
       "      <th>Actor2Type1Code</th>\n",
       "      <th>Actor1Geo_CountryCode</th>\n",
       "      <th>Actor2Geo_CountryCode</th>\n",
       "      <th>EventRootCode</th>\n",
       "      <th>AVG(NumMentions)</th>\n",
       "      <th>AVG(AvgTone)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34109</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>COP</td>\n",
       "      <td>INS</td>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>19</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-8.089026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34115</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>ELI</td>\n",
       "      <td>INS</td>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3.412073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34128</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>GOV</td>\n",
       "      <td>GOV</td>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34129</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>GOV</td>\n",
       "      <td>GOV</td>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>03</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.283871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34130</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>GOV</td>\n",
       "      <td>GOV</td>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.844229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SQLDATE Actor1CountryCode Actor2CountryCode Actor1Type1Code  \\\n",
       "34109 2017-05-01               AFG               AFG             COP   \n",
       "34115 2017-05-01               AFG               AFG             ELI   \n",
       "34128 2017-05-01               AFG               AFG             GOV   \n",
       "34129 2017-05-01               AFG               AFG             GOV   \n",
       "34130 2017-05-01               AFG               AFG             GOV   \n",
       "\n",
       "      Actor2Type1Code Actor1Geo_CountryCode Actor2Geo_CountryCode  \\\n",
       "34109             INS                    AF                    AF   \n",
       "34115             INS                    AF                    AF   \n",
       "34128             GOV                    AF                    AF   \n",
       "34129             GOV                    AF                    AF   \n",
       "34130             GOV                    AF                    AF   \n",
       "\n",
       "      EventRootCode  AVG(NumMentions)  AVG(AvgTone)  \n",
       "34109            19              14.6     -8.089026  \n",
       "34115            11               5.0     -3.412073  \n",
       "34128            02               6.0      1.463415  \n",
       "34129            03              16.0     -0.283871  \n",
       "34130            04               6.0      1.844229  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdelt.dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get a general idea of the distribution of the variable we're attemping to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AvgTone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-14049e61c457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgdelt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AVG(AvgTone)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAvgTone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'AvgTone' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdelt['AVG(AvgTone)'].hist(bins=30);\n",
    "plt.xlabel(\"AvgTone\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it is approximately normal, with a minor left skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the last section, the data has already been aggregated up to find means of our AvgTone and NumMentions columns. In this section we will explore the features of our dataset and consider various ways engineer them into more predictive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at NumMentions. We will find that this value has a large skew to it, with a majority of values being under 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt['AVG(NumMentions)'].hist(bins=30);\n",
    "plt.xlabel(\"numMentions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help smooth this data, we will normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_samp['norm_NumMentions'] = (example_samp['AVG(NumMentions)'] - example_samp['AVG(NumMentions)'].mean())/ \\\n",
    "                                        example_samp['AVG(NumMentions)'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_samp['norm_NumMentions'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore the distribution of values in the country codes. To effectively visualize this, we first bin some of the rarer codes into their own label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unify_rare_cats(example_samp, \"Actor1CountryCode\", .0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_samp['Actor1CountryCode_unify'].cat.remove_unused_categories() \\\n",
    "                            .value_counts().plot(kind=\"bar\");\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Occurrence Count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are quite a few records without a known country code and that there is a large concentration of occurrences in relatively small percentage of the data. This makes sense, as we would expect places with more of a media presence to generate more exhaustive media coverage of events. It does indicate that we should be careful and generalizing a model over the entire dataset, in case that some features which are unique to a country are not present in others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this analysis for our other categorical columns regarding Actor1 as well as EventRootCode. This procedure can also be repeated for Actor2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unify_rare_cats(example_samp, \"Actor1Type1Code\", .01)\n",
    "unify_rare_cats(example_samp, \"Actor1Geo_CountryCode\", .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actor1Type1Code, Actor1Geo_CountryCode, EventRootCode\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "example_samp['Actor1Type1Code_unify'].cat.remove_unused_categories() \\\n",
    "                .value_counts().plot(kind='bar');\n",
    "plt.xlabel('Type Code');\n",
    "             \n",
    "plt.subplot(1, 3, 2)\n",
    "example_samp['Actor1Geo_CountryCode_unify'].cat.remove_unused_categories() \\\n",
    "                .value_counts().plot(kind='bar');\n",
    "plt.xlabel('Country');\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "example_samp['EventRootCode'].cat.remove_unused_categories() \\\n",
    "                .value_counts().plot(kind='bar');\n",
    "plt.xlabel('Event Root Code');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the type codes there are quite a few unknowns. Additionally GOV occurs quite often. For Actor1Geo_CountryCode, we see that a lot of actions take place within the United States, but it still pares in comparison to the total amount of actions that occur in countries which appear more rarely. Finally for the EventCodes, our five most common verbs are \"Consult\", \"Make Public Statement\", \"Engage in Diplomatic Cooperation\", \"Express Intent to Cooperate\", and \"Appeal\".\n",
    "\n",
    "So far, our investigation indicates that we have a lot of categorical columns with a lot of missing values. To handle them, we'll create dummy indicator values for each category which does come with the risk of a much higher dimension problem space. We'll also map any unknown values to the value \"UNK\" before training our models. \n",
    "\n",
    "There are some more sophisticated methods of dimensionality reduction we can try with our categories, like only preserving countries which have \"enough\" records, and mapping all others to \"OTHER\". We could also try a more sophisticated method of only preserving those countries which have a statistically significant and large AvgTone difference, as measured by taking the overall mean of all countries as the population mean, and measuring the deviance of a particular country from this mean. However, it turns out that neither of this methods do much to improve predictive accuracy, and so we do not discuss these any further in this report.\n",
    "\n",
    "What we do build our models on is rather simple. We partition our dataset out by \"Actor1CountryCode\", so for example, we build individual models for \"USA\" and \"GBR\". This helps to isolate us from the noise and/or conflicting signals that may arise from different characteristics of countries when involved in some action upon Actor2. \n",
    "\n",
    "If we want further dimensionality reduction, we can also consider \"Actor2CountryCode\" as reduced to whether Actor1 is the same as Actor2. What this means is the country of the actors was the same, and in sense the event was \"Internal\". This distinction appears to capture a lot of the variance contributed by the \"Actor2CountryCode\" column, but we will achieve higher accuracy including the full range of values. We have a lot of data, and so the dimensionality increase can be compensated for, at the expense of additional compute time.\n",
    "\n",
    "Finally, we will find that \"Actor1Geo_CountryCode\" and \"Actor2Geo_CountryCode\" appear to explain very little variance in the AvgTone, and so we will quickly omit those columns from our training. This will reduce some of the gain in dimensionality from including \"Actor2CountryCode\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build a relatively small sample of our data to try initial quick model constructions to get an idea of their accuracy. The init_sample function drops the \"SQLDATE\" column, normalizes \"NumMentions\" as \"norm_NumMentions\" and drops the \"NumMentions\" column, and cleans our categories to omit unused categories.\n",
    "\n",
    "We distinguish between \"naive\" samples, which include all of the columns, and \"pared\" samples which omit the colums \"Actor1Geo_CountryCode\" and \"Actor2Geo_CountryCode\". In each set of samples, both naive and pared, we train models on the entire sample, the sample restricting \"Actor1CountryCode\" to \"USA\" and the sample restricting \"Actor1CountryCode\" and mapping \"Actor2CountryCode\" to the boolean of whether Actor1 is the same as Actor2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_samp = init_sample(gdelt, .05)\n",
    "naive_samps = [(\"Naive Sample                               \", test_samp), \n",
    "               (\"Naive, Actor1CC = USA, Actor2CC -> Internal\", ICM_INT_sample(test_samp, 'USA')), \n",
    "               (\"Naive, Actor1CC = USA, Actor2CC Normal     \", ICM_SPEC_sample(test_samp, 'USA'))]\n",
    "pared_samps = [(\"Pared Sample                               \", test_samp), \n",
    "               (\"Pared, Actor1CC = USA, Actor2CC -> Internal\", ICM_INT_sample(test_samp, 'USA')), \n",
    "               (\"Pared, Actor1CC = USA, Actor2CC Normal     \", ICM_SPEC_sample(test_samp, 'USA'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, samps, naive):\n",
    "    print(\"Sample Type                                \", \"Train Set Acc     \", \"Test Set Acc     \")\n",
    "    for samp_name, samp in naive_samps:\n",
    "        regr = clone(model)\n",
    "        if naive:\n",
    "            trs, tes, model, model_samp, _, _ = train_naive(samp, regr)\n",
    "        else:\n",
    "            trs, tes, model, model_samp, _, _ = train_pared(samp, regr)\n",
    "        print(samp_name, \"{:.{}f}           \".format(trs, 5), \"{:.{}f}\".format(tes, 5))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Type                                 Train Set Acc      Test Set Acc     \n",
      "Naive Sample                                0.28935            -3725595943.51249\n",
      "Naive, Actor1CC = USA, Actor2CC -> Internal 0.28388            -2756773909464481792.00000\n",
      "Naive, Actor1CC = USA, Actor2CC Normal      0.29809            -166159611733427617792.00000\n"
     ]
    }
   ],
   "source": [
    "eval_model(linear_model.LinearRegression(), naive_samps, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Type                                 Train Set Acc      Test Set Acc     \n",
      "Naive Sample                                0.28933            0.28109\n",
      "Naive, Actor1CC = USA, Actor2CC -> Internal 0.28292            0.24440\n",
      "Naive, Actor1CC = USA, Actor2CC Normal      0.29632            0.24579\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Type                                \", \"Train Set Acc     \", \"Test Set Acc     \")\n",
    "for samp_name, samp in naive_samps:\n",
    "    regr = Ridge()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, regr)\n",
    "    print(samp_name, \"{:.{}f}           \".format(trs, 5), \"{:.{}f}\".format(tes, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Type                                 Train Set Acc      Test Set Acc     \n",
      "Naive Sample                                0.28933            0.28109\n",
      "Naive, Actor1CC = USA, Actor2CC -> Internal 0.28292            0.24440\n",
      "Naive, Actor1CC = USA, Actor2CC Normal      0.29632            0.24579\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Type                                \", \"Train Set Acc     \", \"Test Set Acc     \")\n",
    "for samp_name, samp in naive_samps:\n",
    "    regr = Ridge()\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, regr)\n",
    "    print(samp_name, \"{:.{}f}           \".format(trs, 5), \"{:.{}f}\".format(tes, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.19628313861021374 0.17333226567732452\n",
      "1 0.24202593211236478 0.09858590555389501\n",
      "2 0.24261801641111336 0.12471991794039627\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "dt = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, dt)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.19628313861021374 0.1714599469965984\n",
      "1 0.24202593211236467 0.10263845201368149\n",
      "2 0.24261801641111336 0.11067761063503523\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "dt = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, dt)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.454002971516422 -0.4223393579632764\n",
      "[LibSVM]1 -0.44213988964612394 -0.5115034390914042\n",
      "[LibSVM]2 -0.3823166895529788 -0.44419578495544143\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "sv = svm.SVR()\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    sv = svm.SVR(max_iter=100, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, sv)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.454002971516422 -0.4223393579632764\n",
      "[LibSVM]1 -0.44213988964612394 -0.5115034390914042\n",
      "[LibSVM]2 -0.3823166895529788 -0.44419578495544143\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "sv = svm.SVR()\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    sv = svm.SVR(max_iter=100, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, sv)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1655744505235709 0.16198411512635835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.21574198239401157 0.1468327130307373\n",
      "2 0.20140454001248886 0.13759870508931737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "rfc = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    rfc = RandomForestRegressor(max_depth=7)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, rfc)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.16053020778765137 0.15710196510214047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.20581983798824355 0.13761248176145313\n",
      "2 0.22066372691273872 0.14977551370050413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "rfc = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    rfc = RandomForestRegressor(max_depth=7)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, rfc)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.23693303395193144 0.2307851373215999 56.33863711357117\n",
      "1 0.29205056078009284 0.18654139472884368 2.336773633956909\n",
      "2 0.29598994599450845 0.1983531069384752 2.7521584033966064\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    start_time = time.time()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.23693303395193144 0.23064582472679152 54.702860832214355\n",
      "1 0.29205056078009284 0.18614356662086418 1.967256784439087\n",
      "2 0.29598994599450845 0.19967377650362672 2.687342643737793\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    start_time = time.time()\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, gbr)\n",
    "    print(idx, trs, tes, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = list(test_samp['Actor1CountryCode'].value_counts().index)\n",
    "small_list = countries[:5]\n",
    "ICM_INT_samps = []\n",
    "ICM_SPEC_samps = []\n",
    "\n",
    "for country in small_list:\n",
    "    ICM_INT_samps.append(ICM_INT_sample(test_samp, country))\n",
    "    ICM_SPEC_samps.append(ICM_SPEC_sample(test_samp, country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretable Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
