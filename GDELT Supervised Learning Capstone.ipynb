{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import csv, sqlite3\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "from GDELT_utils import GDELT_columns, usecols, dtype_dict, \\\n",
    "                        cameo_dict, map_cameo_to_text, \\\n",
    "                        state_dict, mem_usage, state_heat_map, \\\n",
    "                        init_sample, \\\n",
    "                        ICM_INT_sample, ICM_SPEC_sample, \\\n",
    "                        train_naive, train_pared, \\\n",
    "                        train_pared_URARE, train_pared_UWEAK, \\\n",
    "                        country_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdelt = pd.read_csv(\"gdelt_agg_big.csv\",\n",
    "                    dtype={\"EventRootCode\": \"category\",\n",
    "                           \"Actor1CountryCode\": \"category\", \n",
    "                           \"Actor2CountryCode\": \"category\",\n",
    "                           \"Actor1Geo_CountryCode\": \"category\", \n",
    "                           \"Actor2Geo_CountryCode\": \"category\",\n",
    "                           \"Actor1Type1Code\": \"category\",\n",
    "                           \"Actor2Type1Code\": \"category\",\n",
    "                           \"AVG(NumMentions)\": \"float64\",\n",
    "                           \"AVG(AvgTone)\": \"float64\"},\n",
    "                   parse_dates=[\"SQLDATE\"])\n",
    "gdelt = gdelt.drop(labels=gdelt[(gdelt['EventRootCode'] == \"--\")].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samp = init_sample(gdelt, .01)\n",
    "naive_samps = [test_samp, ICM_INT_sample(test_samp, 'USA'), ICM_SPEC_sample(test_samp, 'USA')]\n",
    "pared_samps = [test_samp, ICM_INT_sample(test_samp, 'USA'), ICM_SPEC_sample(test_samp, 'USA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.29383519699434846 -1.4092146273752219e+17\n",
      "1 0.34047090791280743 -6.936461032318225e+17\n",
      "2 0.3718275602793095 -3.9566541260495775e+20\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "regr = linear_model.LinearRegression()\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, regr)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2741580966982158 -8.115183237732866e+16\n",
      "1 0.24656641837275095 0.1547296336727716\n",
      "2 0.30752949439066357 -3.239808676232731e+20\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "regr = linear_model.LinearRegression()\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, regr)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.19628313861021374 0.17333226567732452\n",
      "1 0.24202593211236478 0.09858590555389501\n",
      "2 0.24261801641111336 0.12471991794039627\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "dt = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, dt)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.19628313861021374 0.1714599469965984\n",
      "1 0.24202593211236467 0.10263845201368149\n",
      "2 0.24261801641111336 0.11067761063503523\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "dt = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, dt)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.454002971516422 -0.4223393579632764\n",
      "[LibSVM]1 -0.44213988964612394 -0.5115034390914042\n",
      "[LibSVM]2 -0.3823166895529788 -0.44419578495544143\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "sv = svm.SVR()\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    sv = svm.SVR(max_iter=100, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, sv)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.istre91\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.454002971516422 -0.4223393579632764\n",
      "[LibSVM]1 -0.44213988964612394 -0.5115034390914042\n",
      "[LibSVM]2 -0.3823166895529788 -0.44419578495544143\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "sv = svm.SVR()\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    sv = svm.SVR(max_iter=100, verbose=True)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, sv)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1655744505235709 0.16198411512635835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.21574198239401157 0.1468327130307373\n",
      "2 0.20140454001248886 0.13759870508931737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "rfc = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    rfc = RandomForestRegressor(max_depth=7)\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, rfc)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 3:\n",
    "        good1, good1_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.16053020778765137 0.15710196510214047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.20581983798824355 0.13761248176145313\n",
      "2 0.22066372691273872 0.14977551370050413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "rfc = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    rfc = RandomForestRegressor(max_depth=7)\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, rfc)\n",
    "    print(idx, trs, tes)\n",
    "    if idx == 1:\n",
    "        good2, good2_samp = model, model_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.23693303395193144 0.2307851373215999 56.33863711357117\n",
      "1 0.29205056078009284 0.18654139472884368 2.336773633956909\n",
      "2 0.29598994599450845 0.1983531069384752 2.7521584033966064\n"
     ]
    }
   ],
   "source": [
    "good1, good1_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(naive_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    start_time = time.time()\n",
    "    trs, tes, model, model_samp, _, _ = train_naive(samp, gbr)\n",
    "    print(idx, trs, tes, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.23693303395193144 0.23064582472679152 54.702860832214355\n",
      "1 0.29205056078009284 0.18614356662086418 1.967256784439087\n",
      "2 0.29598994599450845 0.19967377650362672 2.687342643737793\n"
     ]
    }
   ],
   "source": [
    "good2, good2_samp = None, None\n",
    "gbr = None\n",
    "for idx, samp in enumerate(pared_samps):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    start_time = time.time()\n",
    "    trs, tes, model, model_samp, _, _ = train_pared(samp, gbr)\n",
    "    print(idx, trs, tes, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = list(test_samp['Actor1CountryCode'].value_counts().index)\n",
    "small_list = countries[:5]\n",
    "ICM_INT_samps = []\n",
    "ICM_SPEC_samps = []\n",
    "\n",
    "for country in small_list:\n",
    "    ICM_INT_samps.append(ICM_INT_sample(test_samp, country))\n",
    "    ICM_SPEC_samps.append(ICM_SPEC_sample(test_samp, country))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
